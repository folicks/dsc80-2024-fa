{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e7bb35",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719face",
   "metadata": {},
   "source": [
    "# Lab 6 â€“ APIs and Web Scraping\n",
    "\n",
    "## DSC 80, Fall 2024\n",
    "\n",
    "### Due Date: Friday, Nov 8th at 11:59 PM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd6168",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the sixth DSC 80 lab this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2024-fa).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.** More details on its usage are given at the bottom of this notebook.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note: </b> For this lab, due to system constraints, the code may take varying amounts of time to run on different machines. If you are able to submit to Gradescope and the code runs, then you have met the runtime requirements.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ac16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e87806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36d971",
   "metadata": {},
   "source": [
    "If the cell below returns a `ModuleNotFoundError`, please run `!pip install lxml` in a new cell. After `lxml` is succesfully installed, go to `kernel` then restart. Note that you will only need to run `!pip install lxml` once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a876bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5a899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609dcc7",
   "metadata": {},
   "source": [
    "## Question 1 â€“ Practice with HTML Tags ðŸ“Ž\n",
    "\n",
    "In Question 2, you'll spend plenty of time parsing HTML source code. But before you get your hands dirty trying to extract information from HTML written by other people, it is a good idea to write basic HTML code yourself. This exercise will help you better understand how the code in a `.html` file is structured.\n",
    "\n",
    "For this question, you'll create a very basic `.html` file, named `lab06_1.html`, that satisfies the following conditions:\n",
    "\n",
    "- It must have `<title>` and `<head>` tags.\n",
    "- It must also have `<body>` tags. Within the `<body>` tags, it must have:\n",
    "    - At least two headers.\n",
    "    * At least three images.\n",
    "        - At least one image must be a local file.\n",
    "        - At least one image must be linked to online source.\n",
    "        - At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages.\n",
    "    * At least one table with two rows and two columns.\n",
    "    \n",
    "\n",
    "Make sure to save your file as `lab06_1.html`, and save it in the same directory as `lab.py`. **When submitting this homework to Gradescope, make sure to also upload `lab06_1.html` along with the local image that you embedded in your site.** You can upload multiple files to Gradescope at a time.\n",
    "   \n",
    "\n",
    "***Notes***:\n",
    "- You can write and view basic HTML with a Jupyter Notebook, using either a Markdown cell or by using the `IPython.display.HTML` function (which takes in a string of HTML and renders it).\n",
    "- If you write your HTML code within a Jupyter Notebook, you should later copy your code into a text editor and save it with the `.html` extension. You could also write your HTML in a text editor directly.\n",
    "- Be sure to open your final `.html` file in a browser and make sure it looks correct on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f44934d-c51f-413d-a84a-f4e15037ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 60B0-457A\n",
      "\n",
      " Directory of C:\\Users\\najer\\OneDrive - UC San Diego\\fall_2024\\dsc_80\\dsc80-2024-fa\\labs\\lab06\n",
      "\n",
      "11/09/2024  10:20 PM    <DIR>          .\n",
      "11/09/2024  10:18 PM    <DIR>          ..\n",
      "11/09/2024  10:20 PM    <DIR>          .ipynb_checkpoints\n",
      "11/09/2024  10:20 PM            28,347 .OTTER_LOG\n",
      "11/02/2024  07:31 PM    <DIR>          __pycache__\n",
      "11/09/2024  10:44 AM          (98,942) books_data.csv\n",
      "11/02/2024  07:28 PM    <DIR>          data\n",
      "11/18/2023  06:36 PM             5,939 HokaOneOne-Logo.png\n",
      "11/09/2024  10:20 PM           122,924 lab.ipynb\n",
      "11/02/2024  07:27 PM             1,447 lab.py\n",
      "11/04/2024  09:01 PM           (1,309) lab06_scratch.py\n",
      "11/02/2024  07:27 PM             2,234 lab-validation.py\n",
      "11/09/2024  10:03 PM             1,205 output.html\n",
      "               8 File(s)        262,347 bytes\n",
      "               5 Dir(s)  13,778,493,440 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea5142-716d-4bf3-9a94-50f1bed92fc3",
   "metadata": {},
   "source": [
    "<head><h1><title>Hello I'm Felix</title></h1></head>\n",
    "\n",
    "<body>\n",
    "    <head>secular cover of 01101111 01101110 01100101 </head>\n",
    "    <div>\n",
    "\n",
    "<p>please non-denominational deity help me</p>\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div>\n",
    "\n",
    "<img src = \"/HokaOneOne-Logo.png\" alt=\"there should be an image here\">\n",
    "<img src = \"HokaOneOne-Logo.png\" >\n",
    "\n",
    "\n",
    "<img>https://lastfm.freetls.fastly.net/i/u/300x300/d879c6dfd226879b9d60d08df3465ab3.jpg</img>\n",
    "\n",
    "<a>https://learningds.org/ch/14/web_html.html</a>\n",
    "\n",
    "\n",
    "<a>https://www.google.com/imgres?q=metallica%20super%20mario%2064%20soundfont%20and%20justice%20for%20all%20cover&imgurl=https%3A%2F%2Fi.ytimg.com%2Fvi%2FRXd75NJFmdE%2Fmaxresdefault.jpg&imgrefurl=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DRXd75NJFmdE&docid=R5WSdoEFoPX1EM&tbnid=k2n9mLrsSm2fcM&vet=12ahUKEwiUhdiXor-JAxX-LkQIHc2mBsMQM3oECBsQAA..i&w=1280&h=720&hcb=2&ved=2ahUKEwiUhdiXor-JAxX-LkQIHc2mBsMQM3oECBsQAA\n",
    "</a>\n",
    "\n",
    "<a>https://emojipedia.org/loudly-crying-face</a>\n",
    "</div>\n",
    "    \n",
    "<head>this is table arbitrarily arranged of sorta the lyrics</head>\n",
    "<table>\n",
    "<tbody>\n",
    "            <tr>\n",
    "                <th>index</th><th>prefix</th><th>suffix</th> \n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>0</td><td>can't afford tuition</td><td>lol</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>1</td><td>nothing is real but</td><td>bills</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e22f7-3999-4bdd-9632-10a561b835e6",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tbody>\n",
    "  <tr>\n",
    "   <th>A</th><th>B</th><th>C</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>1</td><td>2</td><td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "   <td>5</td><td>6</td><td>7</td>\n",
    "  </tr>\n",
    " </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfeb479c-52ff-4d90-a40e-fc642456ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = \"\"\"<head><h1><title>Hello I'm Felix</title></h1></head>\n",
    "\n",
    "<body>\n",
    "    <head>secular cover of 01101111 01101110 01100101 </head>\n",
    "    <div>\n",
    "\n",
    "<p>please non-denominational deity help me</p>\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div>\n",
    "\n",
    "<img src = \"/HokaOneOne-Logo.png\" alt=\"there should be an image here\">\n",
    "<img src = \"HokaOneOne-Logo.png\">\n",
    "\n",
    "\n",
    "<img>https://lastfm.freetls.fastly.net/i/u/300x300/d879c6dfd226879b9d60d08df3465ab3.jpg</img>\n",
    "\n",
    "<a>https://learningds.org/ch/14/web_html.html</a>\n",
    "\n",
    "\n",
    "<a>https://www.google.com/imgres?q=metallica%20super%20mario%2064%20soundfont%20and%20justice%20for%20all%20cover&imgurl=https%3A%2F%2Fi.ytimg.com%2Fvi%2FRXd75NJFmdE%2Fmaxresdefault.jpg&imgrefurl=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DRXd75NJFmdE&docid=R5WSdoEFoPX1EM&tbnid=k2n9mLrsSm2fcM&vet=12ahUKEwiUhdiXor-JAxX-LkQIHc2mBsMQM3oECBsQAA..i&w=1280&h=720&hcb=2&ved=2ahUKEwiUhdiXor-JAxX-LkQIHc2mBsMQM3oECBsQAA\n",
    "</a>\n",
    "\n",
    "<a>https://emojipedia.org/loudly-crying-face</a>\n",
    "</div>\n",
    "    \n",
    "<head>this is table arbitrarily arranged of sorta the lyrics</head>\n",
    "<table>\n",
    "<tbody>\n",
    "            <tr>\n",
    "                <th>index</th><th>prefix</th><th>suffix</th> \n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>0</td><td>can't afford tuition</td><td>lol</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>1</td><td>nothing is real but</td><td>bills</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</body>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765d3d4a-b702-4d93-b8be-476fa3a6dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03792514-52f6-4db0-9ff0-3930533e337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Assuming you have your markdown content in a variable called 'markdown_content'\n",
    "html_content = markdown.markdown(markdown_content)\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "# Get the body content\n",
    "body_content = str(soup.body)\n",
    "# body_content\n",
    "# # Write to file\n",
    "with open('lab06_1.html', 'w') as f:\n",
    "    f.write(body_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5e7178-5259-427e-a949-09c3f1fc3778",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InteractiveShell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m html_output \u001b[38;5;241m=\u001b[39m \u001b[43mInteractiveShell\u001b[49m\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mdisplay_formatter\u001b[38;5;241m.\u001b[39mformat(Markdown(markdown_content))\n\u001b[0;32m      2\u001b[0m html_output[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'InteractiveShell' is not defined"
     ]
    }
   ],
   "source": [
    "html_output = InteractiveShell.instance().display_formatter.format(Markdown(markdown_content))\n",
    "html_output[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d1e73806-1011-42bf-b332-0ac34cc05453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Your markdown content\n",
    "# markdown_text = \"# This is a heading\\n\\nThis is some **bold** text.\"\n",
    "\n",
    "# Render markdown to HTML\n",
    "html_output = InteractiveShell.instance().display_formatter.format(Markdown(markdown_content))[0]['text/markdown']\n",
    "\n",
    "# Save to file\n",
    "with open('lab06_1.html', 'w') as f:\n",
    "    f.write(html_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ec7665e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't delete this cell!\n",
    "question1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cdb35f79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1855cc",
   "metadata": {},
   "source": [
    "## Question 2 â€“ Scraping an Online Bookstore ðŸ“š\n",
    "\n",
    "Browse through the following fake online bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Your job is to scrape the website, collecting data on all books that have:\n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than Â£50**, and \n",
    "- **belong to specific categories** (more details below). \n",
    "\n",
    "You will extract the information into a DataFrame that looks like the one below.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>UPC</th>\n",
    "      <th>Product Type</th>\n",
    "      <th>Price (excl. tax)</th>\n",
    "      <th>Price (incl. tax)</th>\n",
    "      <th>Tax</th>\n",
    "      <th>Availability</th>\n",
    "      <th>Number of reviews</th>\n",
    "      <th>Category</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Description</th>\n",
    "      <th>Title</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>e10e1e165dc8be4a</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£22.60</td>\n",
    "      <td>Ã‚Â£22.60</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Default</td>\n",
    "      <td>Four</td>\n",
    "      <td>For readers of Laura Hillenbrand's Seabiscuit...</td>\n",
    "      <td>The Boys in the Boat: Nine Americans...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>c2e46a2ee3b4a322</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£25.27</td>\n",
    "      <td>Ã‚Â£25.27</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>A Michelin two-star chef at twenty-eight, Violette...</td>\n",
    "      <td>Chase Me (Paris Nights #2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>00bfed9e18bb36f3</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£34.53</td>\n",
    "      <td>Ã‚Â£34.53</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>No matter how busy he keeps himself...</td>\n",
    "      <td>Black Dust</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "To do so, implement the following functions.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `extract_book_links`\n",
    "\n",
    "Complete the implementation of the function `extract_book_links`, which takes in the content of a page that contains book listings as a **string of HTML**, and returns a **list** of URLs of book-specific pages for all books with **_at least_ a four-star rating and a price _strictly_ less than Â£50**.\n",
    "\n",
    "For this method, the URLs you return should not contain the protocol (i.e. `'https://'`). The protocols should be added back into the URLs when you actually make the requests.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `get_product_info`\n",
    "\n",
    "Complete the implementation of the function `get_product_info`, which takes in the content of a book-specific page as a **string of HTML**, and a list `categories` of book categories. If the input book is in the list of `categories`, `get_product_info` should return a dictionary corresponding to a row in the DataFrame in the image above (where the keys are the column names and the values are the row values). If the input book is not in the list of `categories`, return `None`. <b> The order of the dictionary keys does not matter. </b>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `scrape_books`\n",
    "\n",
    "Finally, put everything together. Complete the implementation of the function `scrape_books`, which takes in an integer `k` and a list `categories` of book categories. `scrape_books` should use `requests` to scrape the first `k` pages of the bookstore and return a DataFrame of only the books that have:\n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than Â£50**, and\n",
    "- **a category that is in the list `categories`**.\n",
    "\n",
    "<b> The order of the DataFrame columns does not matter. </b>\n",
    "\n",
    "<br>\n",
    "\n",
    "Some general guidance and tips:\n",
    "\n",
    "- The first page of the bookstore is at http://books.toscrape.com/catalogue/page-1.html. Subsequent pages can be found by clicking the \"Next\" button at the bottom of the page. Look at how the URLs change each time you navigate to a new page; think about how to use f-strings (or some other string formatting technique) to generate these URLs.\n",
    "- Use \"inspect element\" to view the source code of the pages you're trying to scrape. To find a book's category, look at the hyperlinks in the book-specific page for that book.\n",
    "- **`scrape_books` should run in under 180 seconds on the entire bookstore (`k = 50`). `scrape_books` is also the only function that should make `GET` requests; the other two functions parse already-existing HTML.**\n",
    "- When instantiating `bs4.BeautifulSoup` objects, use the optional argument `features='lxml'` to suppress any warnings.\n",
    "- Don't worry about typecasting, i.e. it's fine if `'Number of reviews'` is not stored as type `int`. Also, don't worry if you run into encoding errors in your price columns (as the example DataFrame at the top of this cell contains)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4242e0-6f12-4e64-9203-c45fd5a1968f",
   "metadata": {},
   "source": [
    "## DONT render the HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438e8bd1-cfba-4238-bb6c-5c39c30cc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_links():\n",
    "\n",
    "\n",
    "    '''\n",
    "    use f-string to loop thru the pages for (k amount this will be obtained from scrape_books)\n",
    "    suffixing the url -page1, -page2, etc.\n",
    "    \n",
    "    '''\n",
    "    # the only function to contain a request thus MUST loop here from scrape_books\n",
    "\n",
    "\n",
    "    # example looping usage\n",
    "    # res_clash = requests.get(\n",
    "    #     BASE_URL + \"artists/\" + artist_id + \"/albums\",\n",
    "    #     headers=headers,\n",
    "    #     params={\"include_groups\": \"album\"},\n",
    "    # )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e20e85-19f9-436d-b98c-865a26648fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"star-rating One\">\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "bookstore_home = 'http://books.toscrape.com/'\n",
    "req_bookstore_home = requests.get(bookstore_home)\n",
    "bookstore_home_html = bs4.BeautifulSoup(req_bookstore_home.text,\"html.parser\")\n",
    "# what should i be putting in the BeautifulSoup argument?\n",
    "print(\n",
    "    (bookstore_home_html.find(\"p\", attrs ={\"class\":\"star-rating One\"} ))\n",
    "    \n",
    "     \n",
    "    )\n",
    "\n",
    "# how would i find the actual listing belonging to the rating /price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766145f4-eb79-4068-8f01-6ceddb64d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sharp Objects, Rating: 4 stars, Price: Â£47.82\n",
      "Title: The Dirty Little Secrets of Getting Your Dream Job, Rating: 4 stars, Price: Â£33.34\n",
      "Title: The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics, Rating: 4 stars, Price: Â£22.6\n",
      "Title: Shakespeare's Sonnets, Rating: 4 stars, Price: Â£20.66\n",
      "Title: Set Me Free, Rating: 5 stars, Price: Â£17.46\n",
      "Title: Rip it Up and Start Again, Rating: 5 stars, Price: Â£35.02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# URL to scrape\n",
    "url = \"http://books.toscrape.com/\"\n",
    "\n",
    "# Send a request to the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check that the request was successful\n",
    "\n",
    "# Parse the page content with BeautifulSoup\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Dictionary to map class names to numeric ratings\n",
    "rating_map = {\n",
    "    \"One\": 1,\n",
    "    \"Two\": 2,\n",
    "    \"Three\": 3,\n",
    "    \"Four\": 4,\n",
    "    \"Five\": 5\n",
    "}\n",
    "\n",
    "# Find all books with a 4 or 5-star rating\n",
    "filtered_books = []\n",
    "for article in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "    # Find the rating class in the <p> tag\n",
    "    rating_class = article.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "    # Convert the rating class to a numeric value\n",
    "    rating = rating_map.get(rating_class, 0)\n",
    "    \n",
    "    # Check if the rating is 4 or higher\n",
    "    if rating >= 4:\n",
    "        # Get the title of the book\n",
    "        title = article.find(\"h3\").a[\"title\"]\n",
    "        # Get the price of the book\n",
    "        price_text = article.find(\"p\", class_=\"price_color\").text\n",
    "\n",
    "        # high_rated_books.append((title, price_text))\n",
    "        price = float(price_text[2:])  # Remove the currency symbol (Â£) and convert to float\n",
    "\n",
    "        # Check if the price is under 50\n",
    "        if price < 50:\n",
    "            filtered_books.append((title, rating, price))\n",
    "\n",
    "# Print the results\n",
    "\n",
    "# for book in high_rated_books:\n",
    "#     print(f\"Title: {book[0]}, Rating: {book[1]} stars\")\n",
    "\n",
    "for book in filtered_books:\n",
    "    print(f\"Title: {book[0]}, Rating: {book[1]} stars, Price: Â£{book[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccacf6f9-9bb1-4511-a900-c8307c447369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL for the website\n",
    "base_url = \"http://books.toscrape.com/\"\n",
    "\n",
    "# Map for rating text to numerical ratings\n",
    "rating_map = {\n",
    "    \"One\": 1,\n",
    "    \"Two\": 2,\n",
    "    \"Three\": 3,\n",
    "    \"Four\": 4,\n",
    "    \"Five\": 5\n",
    "}\n",
    "\n",
    "# Categories to filter (update as per requirement)\n",
    "target_categories = [\"Romance\", \"Historical Fiction\", \"Science\", \"Default\"]  # Example categories\n",
    "\n",
    "# List to store book data\n",
    "books_data = []\n",
    "\n",
    "# Function to get book details from its page\n",
    "def get_book_details(book_url):\n",
    "    response = requests.get(book_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Extract information from the product table\n",
    "    table = soup.find(\"table\", class_=\"table table-striped\")\n",
    "    product_info = {row.th.text: row.td.text for row in table.find_all(\"tr\")}\n",
    "    \n",
    "    # Extract specific fields\n",
    "    upc = product_info.get(\"UPC\", \"\")\n",
    "    product_type = product_info.get(\"Product Type\", \"\")\n",
    "    price_excl_tax = product_info.get(\"Price (excl. tax)\", \"\")\n",
    "    price_incl_tax = product_info.get(\"Price (incl. tax)\", \"\")\n",
    "    tax = product_info.get(\"Tax\", \"\")\n",
    "    availability = product_info.get(\"Availability\", \"\")\n",
    "    number_of_reviews = product_info.get(\"Number of reviews\", \"0\")\n",
    "    \n",
    "    # Extract description, if available\n",
    "    description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    description_text = description[\"content\"].strip() if description else \"\"\n",
    "    \n",
    "    # Extract category\n",
    "    category = soup.find(\"ul\", class_=\"breadcrumb\").find_all(\"a\")[-1].text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"UPC\": upc,\n",
    "        \"Product Type\": product_type,\n",
    "        \"Price (excl. tax)\": price_excl_tax,\n",
    "        \"Price (incl. tax)\": price_incl_tax,\n",
    "        \"Tax\": tax,\n",
    "        \"Availability\": availability,\n",
    "        \"Number of reviews\": number_of_reviews,\n",
    "        \"Category\": category,\n",
    "        \"Description\": description_text\n",
    "    }\n",
    "\n",
    "# Function to scrape each book from the main page\n",
    "def scrape_books():\n",
    "    page_url = base_url + \"catalogue/page-1.html\"\n",
    "    while True:\n",
    "        response = requests.get(page_url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Find all book entries\n",
    "        for article in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "            # Extract rating\n",
    "            rating_class = article.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "            rating = rating_map.get(rating_class, 0)\n",
    "            \n",
    "            # Filter by rating\n",
    "            if rating < 4:\n",
    "                continue\n",
    "\n",
    "            # Extract price and filter by price\n",
    "            price_text = article.find(\"p\", class_=\"price_color\").text\n",
    "            price = float(price_text[2:])\n",
    "            if price >= 50:\n",
    "                continue\n",
    "            \n",
    "            # Extract title and link to book details\n",
    "            title = article.find(\"h3\").a[\"title\"]\n",
    "            book_url = base_url + \"catalogue/\" + article.find(\"h3\").a[\"href\"]\n",
    "\n",
    "            # Get additional details from the book's page\n",
    "            book_details = get_book_details(book_url)\n",
    "            \n",
    "            # Check if the category matches the target categories\n",
    "            if book_details[\"Category\"] not in target_categories:\n",
    "                continue\n",
    "\n",
    "            # Add the book to the list\n",
    "            books_data.append({\n",
    "                \"UPC\": book_details[\"UPC\"],\n",
    "                \"Product Type\": book_details[\"Product Type\"],\n",
    "                \"Price (excl. tax)\": book_details[\"Price (excl. tax)\"],\n",
    "                \"Price (incl. tax)\": book_details[\"Price (incl. tax)\"],\n",
    "                \"Tax\": book_details[\"Tax\"],\n",
    "                \"Availability\": book_details[\"Availability\"],\n",
    "                \"Number of reviews\": book_details[\"Number of reviews\"],\n",
    "                \"Category\": book_details[\"Category\"],\n",
    "                \"Rating\": rating_class,\n",
    "                \"Description\": book_details[\"Description\"],\n",
    "                \"Title\": title\n",
    "            })\n",
    "\n",
    "        # Find next page\n",
    "        next_button = soup.find(\"li\", class_=\"next\")\n",
    "        if next_button:\n",
    "            next_page = next_button.a[\"href\"]\n",
    "            page_url = base_url + \"catalogue/\" + next_page\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1f0f55-35a1-47c1-a345-5e936c851b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e10e1e165dc8be4a</td>\n",
       "      <td>Books</td>\n",
       "      <td>Ã‚Â£22.60</td>\n",
       "      <td>Ã‚Â£22.60</td>\n",
       "      <td>Ã‚Â£0.00</td>\n",
       "      <td>In stock (19 available)</td>\n",
       "      <td>0</td>\n",
       "      <td>Default</td>\n",
       "      <td>Four</td>\n",
       "      <td>For readers of Laura Hillenbrand's Seabiscuit ...</td>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2e46a2ee3b4a322</td>\n",
       "      <td>Books</td>\n",
       "      <td>Ã‚Â£25.27</td>\n",
       "      <td>Ã‚Â£25.27</td>\n",
       "      <td>Ã‚Â£0.00</td>\n",
       "      <td>In stock (19 available)</td>\n",
       "      <td>0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Five</td>\n",
       "      <td>A Michelin two-star chef at twenty-eight, Viol...</td>\n",
       "      <td>Chase Me (Paris Nights #2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00bfed9e18bb36f3</td>\n",
       "      <td>Books</td>\n",
       "      <td>Ã‚Â£34.53</td>\n",
       "      <td>Ã‚Â£34.53</td>\n",
       "      <td>Ã‚Â£0.00</td>\n",
       "      <td>In stock (19 available)</td>\n",
       "      <td>0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Five</td>\n",
       "      <td>No matter how busy he keeps himself, successfu...</td>\n",
       "      <td>Black Dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadee1c326d286e3</td>\n",
       "      <td>Books</td>\n",
       "      <td>Ã‚Â£42.96</td>\n",
       "      <td>Ã‚Â£42.96</td>\n",
       "      <td>Ã‚Â£0.00</td>\n",
       "      <td>In stock (16 available)</td>\n",
       "      <td>0</td>\n",
       "      <td>Science</td>\n",
       "      <td>Four</td>\n",
       "      <td>Renowned ornithologist Tim Birkhead opens this...</td>\n",
       "      <td>The Most Perfect Thing: Inside (and Outside) a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8c9e6bf2467d740d</td>\n",
       "      <td>Books</td>\n",
       "      <td>Ã‚Â£20.59</td>\n",
       "      <td>Ã‚Â£20.59</td>\n",
       "      <td>Ã‚Â£0.00</td>\n",
       "      <td>In stock (16 available)</td>\n",
       "      <td>0</td>\n",
       "      <td>Default</td>\n",
       "      <td>Five</td>\n",
       "      <td>Slay Procrastination, Distraction, and Overwhe...</td>\n",
       "      <td>The Inefficiency Assassin: Time Management Tac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                UPC Product Type Price (excl. tax) Price (incl. tax)     Tax  \\\n",
       "0  e10e1e165dc8be4a        Books           Ã‚Â£22.60           Ã‚Â£22.60  Ã‚Â£0.00   \n",
       "1  c2e46a2ee3b4a322        Books           Ã‚Â£25.27           Ã‚Â£25.27  Ã‚Â£0.00   \n",
       "2  00bfed9e18bb36f3        Books           Ã‚Â£34.53           Ã‚Â£34.53  Ã‚Â£0.00   \n",
       "3  aadee1c326d286e3        Books           Ã‚Â£42.96           Ã‚Â£42.96  Ã‚Â£0.00   \n",
       "4  8c9e6bf2467d740d        Books           Ã‚Â£20.59           Ã‚Â£20.59  Ã‚Â£0.00   \n",
       "\n",
       "              Availability Number of reviews Category Rating  \\\n",
       "0  In stock (19 available)                 0  Default   Four   \n",
       "1  In stock (19 available)                 0  Romance   Five   \n",
       "2  In stock (19 available)                 0  Romance   Five   \n",
       "3  In stock (16 available)                 0  Science   Four   \n",
       "4  In stock (16 available)                 0  Default   Five   \n",
       "\n",
       "                                         Description  \\\n",
       "0  For readers of Laura Hillenbrand's Seabiscuit ...   \n",
       "1  A Michelin two-star chef at twenty-eight, Viol...   \n",
       "2  No matter how busy he keeps himself, successfu...   \n",
       "3  Renowned ornithologist Tim Birkhead opens this...   \n",
       "4  Slay Procrastination, Distraction, and Overwhe...   \n",
       "\n",
       "                                               Title  \n",
       "0  The Boys in the Boat: Nine Americans and Their...  \n",
       "1                         Chase Me (Paris Nights #2)  \n",
       "2                                         Black Dust  \n",
       "3  The Most Perfect Thing: Inside (and Outside) a...  \n",
       "4  The Inefficiency Assassin: Time Management Tac...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start scraping\n",
    "scrape_books()\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "df = pd.DataFrame(books_data)\n",
    "df.to_csv(\"books_data.csv\", index=False)\n",
    "\n",
    "(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17cf3b49-df8a-4071-ae5c-cac5f5825d96",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1462008021.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def get_product_info():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84878afd-564a-4392-8c58-89f5f01850d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00705bbb-2275-43e9-a1e3-5aa21777473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572de446-c93c-4fd1-929a-53a9c239fdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99d7253b-5661-4a13-9c41-3ac0e8688069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_book_links(page_content):\n",
    "    soup = BeautifulSoup(page_content, 'lxml')\n",
    "    book_links = []\n",
    "\n",
    "    # Map star rating text to numbers\n",
    "    rating_map = {\n",
    "        \"One\": 1,\n",
    "        \"Two\": 2,\n",
    "        \"Three\": 3,\n",
    "        \"Four\": 4,\n",
    "        \"Five\": 5\n",
    "    }\n",
    "\n",
    "    # Loop through each book on the page\n",
    "    for article in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "        # Check rating\n",
    "        rating_class = article.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "        rating = rating_map.get(rating_class, 0)\n",
    "        \n",
    "        # Check price\n",
    "        price_text = article.find(\"p\", class_=\"price_color\").text\n",
    "        price = float(price_text[2:])  # Remove the Â£ symbol and convert to float\n",
    "        \n",
    "        if rating >= 4 and price < 50:\n",
    "            # Extract the URL and strip the protocol\n",
    "            link = article.find(\"h3\").a[\"href\"]\n",
    "            book_links.append(link.lstrip(\"/\"))\n",
    "    \n",
    "    return book_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f166de9a-40a8-4ff3-904b-a1f547a05041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(book_page_content, categories):\n",
    "    soup = BeautifulSoup(book_page_content, 'lxml')\n",
    "    \n",
    "    # Extract category\n",
    "    category = soup.find(\"ul\", class_=\"breadcrumb\").find_all(\"a\")[-1].text.strip()\n",
    "    \n",
    "    # Return None if the category is not in the target categories\n",
    "    if category not in categories:\n",
    "        return None\n",
    "\n",
    "    # Extract information from the product table\n",
    "    table = soup.find(\"table\", class_=\"table table-striped\")\n",
    "    product_info = {row.th.text: row.td.text for row in table.find_all(\"tr\")}\n",
    "\n",
    "    # Extract specific fields\n",
    "    upc = product_info.get(\"UPC\", \"\")\n",
    "    product_type = product_info.get(\"Product Type\", \"\")\n",
    "    price_excl_tax = product_info.get(\"Price (excl. tax)\", \"\")\n",
    "    price_incl_tax = product_info.get(\"Price (incl. tax)\", \"\")\n",
    "    tax = product_info.get(\"Tax\", \"\")\n",
    "    availability = product_info.get(\"Availability\", \"\")\n",
    "    number_of_reviews = product_info.get(\"Number of reviews\", \"0\")\n",
    "    \n",
    "    # Extract description, if available\n",
    "    description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    description_text = description[\"content\"].strip() if description else \"\"\n",
    "    \n",
    "    # Extract title\n",
    "    title = soup.find(\"h1\").text.strip()\n",
    "\n",
    "    # Extract rating\n",
    "    rating_class = soup.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "\n",
    "    # Construct the dictionary\n",
    "    book_info = {\n",
    "        \"UPC\": upc,\n",
    "        \"Product Type\": product_type,\n",
    "        \"Price (excl. tax)\": price_excl_tax,\n",
    "        \"Price (incl. tax)\": price_incl_tax,\n",
    "        \"Tax\": tax,\n",
    "        \"Availability\": availability,\n",
    "        \"Number of reviews\": number_of_reviews,\n",
    "        \"Category\": category,\n",
    "        \"Rating\": rating_class,\n",
    "        \"Description\": description_text,\n",
    "        \"Title\": title\n",
    "    }\n",
    "\n",
    "    return book_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a79b58fc-c6bf-48ae-b7cc-4c01e7edd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_books(k, categories):\n",
    "    base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "    books_data = []\n",
    "\n",
    "    for page in range(1, k + 1):\n",
    "        # Get page content\n",
    "        page_url = base_url.format(page)\n",
    "        response = requests.get(page_url)\n",
    "        \n",
    "        # If the page is not found, break out of the loop\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "\n",
    "        # Extract book links from the current page\n",
    "        book_links = extract_book_links(response.text)\n",
    "\n",
    "        for link in book_links:\n",
    "            # Get the full URL for each book\n",
    "            book_url = \"http://books.toscrape.com/catalogue/\" + link\n",
    "            book_response = requests.get(book_url)\n",
    "            \n",
    "            # Get book information\n",
    "            book_info = get_product_info(book_response.text, categories)\n",
    "            \n",
    "            # Only append if book_info is not None (it met category criteria)\n",
    "            if book_info:\n",
    "                books_data.append(book_info)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(books_data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04aaef-9607-4ca7-8d69-41e684ec0ba5",
   "metadata": {},
   "source": [
    "## _real possible solutions that may be needed for possible redemption_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ee1e1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# def extract_book_links(page_content):\n",
    "#     soup = BeautifulSoup(page_content, 'lxml')\n",
    "#     book_links = []\n",
    "#     rating_map = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
    "\n",
    "#     # Find all book elements\n",
    "#     for article in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "#         # Extract the star rating\n",
    "#         rating_class = article.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "#         rating = rating_map.get(rating_class, 0)\n",
    "        \n",
    "#         # Extract the price\n",
    "#         price_text = article.find(\"p\", class_=\"price_color\").text\n",
    "#         price = float(price_text[1:])  # Remove 'Â£' symbol and convert to float\n",
    "        \n",
    "#         # Check rating and price criteria\n",
    "#         if rating >= 4 and price < 50:\n",
    "#             # Extract book link\n",
    "#             link = article.find(\"h3\").a[\"href\"]\n",
    "#             book_links.append(link.lstrip(\"/\"))  # Remove leading slash for relative URL\n",
    "\n",
    "#     return book_links\n",
    "# def get_product_info(book_page_content, categories):\n",
    "#     soup = BeautifulSoup(book_page_content, 'lxml')\n",
    "\n",
    "#     # Extract category\n",
    "#     category = soup.find(\"ul\", class_=\"breadcrumb\").find_all(\"a\")[-1].text.strip()\n",
    "\n",
    "#     # Return None if the category doesn't match\n",
    "#     if category not in categories:\n",
    "#         return None\n",
    "\n",
    "#     # Extract information from product table\n",
    "#     table = soup.find(\"table\", class_=\"table table-striped\")\n",
    "#     product_info = {row.th.text: row.td.text for row in table.find_all(\"tr\")}\n",
    "    \n",
    "#     # Extract fields\n",
    "#     upc = product_info.get(\"UPC\", \"\")\n",
    "#     product_type = product_info.get(\"Product Type\", \"\")\n",
    "#     price_excl_tax = product_info.get(\"Price (excl. tax)\", \"\")\n",
    "#     price_incl_tax = product_info.get(\"Price (incl. tax)\", \"\")\n",
    "#     tax = product_info.get(\"Tax\", \"\")\n",
    "#     availability = product_info.get(\"Availability\", \"\")\n",
    "#     number_of_reviews = product_info.get(\"Number of reviews\", \"0\")\n",
    "\n",
    "#     # Extract description\n",
    "#     description_meta = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "#     description = description_meta[\"content\"].strip() if description_meta else \"\"\n",
    "    \n",
    "#     # Extract title and rating\n",
    "#     title = soup.find(\"h1\").text.strip()\n",
    "#     rating_class = soup.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "\n",
    "#     return {\n",
    "#         \"UPC\": upc,\n",
    "#         \"Product Type\": product_type,\n",
    "#         \"Price (excl. tax)\": price_excl_tax,\n",
    "#         \"Price (incl. tax)\": price_incl_tax,\n",
    "#         \"Tax\": tax,\n",
    "#         \"Availability\": availability,\n",
    "#         \"Number of reviews\": number_of_reviews,\n",
    "#         \"Category\": category,\n",
    "#         \"Rating\": rating_class,\n",
    "#         \"Description\": description,\n",
    "#         \"Title\": title\n",
    "#     }\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# def scrape_books(k, categories):\n",
    "#     base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "#     all_books = []\n",
    "\n",
    "#     for page_num in range(1, k + 1):\n",
    "#         # Fetch listing page content\n",
    "#         page_url = base_url.format(page_num)\n",
    "#         response = requests.get(page_url)\n",
    "        \n",
    "#         if response.status_code != 200:\n",
    "#             break  # Stop if we run out of pages\n",
    "\n",
    "#         # Get links to books meeting criteria\n",
    "#         book_links = extract_book_links(response.text)\n",
    "\n",
    "#         for relative_link in book_links:\n",
    "#             # Construct full URL and fetch book detail page content\n",
    "#             book_url = f\"http://books.toscrape.com/catalogue/{relative_link}\"\n",
    "#             book_response = requests.get(book_url)\n",
    "\n",
    "#             # Get book info if it matches the categories\n",
    "#             book_info = get_product_info(book_response.text, categories)\n",
    "#             if book_info:\n",
    "#                 all_books.append(book_info)\n",
    "\n",
    "#     # Create DataFrame from collected data\n",
    "#     df = pd.DataFrame(all_books)\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3dad7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0c314ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for extract_book_links \n",
    "extract_book_links_fp = os.path.join('data', 'products.html')\n",
    "extract_book_out = extract_book_links(\n",
    "    open(extract_book_links_fp, encoding='utf-8').read()\n",
    ")\n",
    "extract_book_url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "\n",
    "# doc tests for get product info\n",
    "get_product_info_fp = os.path.join('data', 'Frankenstein.html')\n",
    "get_product_info_out = get_product_info(\n",
    "    open(get_product_info_fp, encoding='utf-8').read(), ['Default']\n",
    ")\n",
    "\n",
    "# public test for scrape books \n",
    "scrape_books_out = scrape_books(1, ['Mystery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "08954b1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ee774",
   "metadata": {},
   "source": [
    "## Question 3 â€“ API Requests ðŸ¤‘\n",
    "\n",
    "You trade stocks as a hobby. As an avid `pandas` coder, you decide to calculate statistics of your favorite stocks by pulling data from a public API. The API we will work with can be found at https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price. Specifically, we will use the \"**Daily Chart EOD**\" endpoint (search for it at the linked page).\n",
    "\n",
    "Some relevant definitions:\n",
    "- Ticker: A short code that refers to a stock. For example, Apple's ticker is AAPL and Ford's ticker is F. \n",
    "- Open: The price of a stock at the beginning of a trading day.\n",
    "- Close: The price of a stock at the end of a trading day.\n",
    "- Volume: The total number of shares traded in a day.\n",
    "- Percent change: The difference in price with respect to the original price, as a percentage.\n",
    "\n",
    "To make requests to the aforementioned API, you will need an API key. In order to get one, you will need to make an account at the website. Once you've signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. You will have to encode your API key in the URL that you make requests to; see a complete example of such a request at the right side of the [documentation](https://site.financialmodelingprep.com/developer/docs#Stock-Historical-Price).\n",
    "\n",
    "Implement the following two functions.\n",
    "\n",
    "#### `stock_history`\n",
    "\n",
    "Complete the implementation of the function `stock_history`, which takes in a string `ticker` and two integers, `year` and `month`, and returns a DataFrame containing the price history for that stock in that month. Keep all of the attributes that are returned by the API.\n",
    "\n",
    "***Notes***:\n",
    "- Read the API documentation if you get stuck!\n",
    "- [`pd.date_range`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html) takes in two dates and returns a sequence of all dates between the two dates, excluding the right endpoint. How might this be helpful?\n",
    "- The [`requests.get`](https://docs.python-requests.org/en/master/user/quickstart/) function returns a Response object, not the data itself. Use the `json` method on the Response object to extract the relevant JSON, as we did in [Lecture 9](https://dsc80.com/resources/lectures/lec09/lec09-filled.html#Example:-GET-requests-via-requests) (you don't need to `import json` to do this).\n",
    "- You can instantiate a DataFrame using a sequence of dictionaries.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `stock_stats`\n",
    "\n",
    "Create a function `stock_stats` that takes in a DataFrame outputted by `stock_history` and returns a **tuple** of two numbers:\n",
    "1. The percent change of the stock throughout the month as a **percentage**.\n",
    "2. An estimate of the total transaction volume **in billion of dollars** for that month.\n",
    "\n",
    "Both values in the tuple should be **strings** that contain numbers rounded to two decimal places. Add a plus or minus sign in front of the percent change, and make sure that the total transaction volume string ends in a `'B'`.\n",
    "\n",
    "**To compute the percent change**, use the opening price on the first day of the month as the starting price and the closing price on the last day of the month as the ending price.\n",
    "\n",
    "**To compute the total transaction volume**, assume that on any given day, the average price of a share is the midpoint of the high and low price for that day.\n",
    "\n",
    "$$ \\text{Estimated Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Average Price} $$\n",
    "\n",
    "For example, suppose there are only three days in March â€“ March 1st, March 2nd, and March 3rd.\n",
    "\n",
    "If BYND (Beyond Meat) opens at \\\\$4 on March 1st and closes at \\\\$5 on March 3rd, its percent change for the month of March is $$\\frac{\\$5-\\$4}{\\$4} = +25.00\\%$$\n",
    "\n",
    "Suppose the high and low prices and volumes of BYND on each day are given below.\n",
    "- March 1st: high \\\\$5, low \\\\$3, volume 500 million (0.5 billion)\n",
    "- March 2nd: high \\\\$5.5, low \\\\$2.5, volume 1 billion\n",
    "- March 3rd: high \\\\$5.25, low \\\\$4, volume 500 million (0.5 billion)\n",
    "\n",
    "Then, the estimated total transaction volume is\n",
    "$$\\frac{\\$5 + \\$3}{2} \\cdot 0.5 B + \\frac{\\$5.5 + \\$2.5}{2} \\cdot 1 B + \\frac{\\$5.25 + \\$4}{2} \\cdot 0.5 B = 8.3125B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cadc06-4b10-46ae-ae06-89dc703281ac",
   "metadata": {},
   "source": [
    "## where do i put my api key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831cae1-82e1-4967-ace7-7fe73685ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need an specific function to cast json array to dataframe\n",
    "# what if the data in the POST isnt json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0175b875-0216-4784-8026-ce5dee60b247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2024-11-04',\n",
       " 'open': 220.99,\n",
       " 'high': 222.79,\n",
       " 'low': 219.71,\n",
       " 'close': 222.01,\n",
       " 'adjClose': 222.01,\n",
       " 'volume': 41727755,\n",
       " 'unadjustedVolume': 41727755,\n",
       " 'change': 1.02,\n",
       " 'changePercent': 0.46156,\n",
       " 'vwap': 221.375,\n",
       " 'label': 'November 04, 24',\n",
       " 'changeOverTime': 0.0046156}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5c1d1-3405-4549-960b-9f5b3d77cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = \"your_api_key\"\n",
    "# url = \"https://api.example.com/data\"\n",
    "# API_KEY = \"TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\"\n",
    "\n",
    "# params = {\n",
    "#     \"api_key\": API_KEY\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6da301e4-d089-4936-a820-5003fe59e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_model_ex_url = 'https://financialmodelingprep.com/api/v3/historical-price-full/AAPL'\n",
    "\n",
    "resp_finance = requests.get(finance_model_ex_url+\"?apikey=TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71561904-bc82-48b2-b9c6-bbdb16546cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data = resp_finance.json()\n",
    "# resp_1500.headers['content-type']\n",
    "    # >>> 'text/html'\n",
    "    # string methods only?\n",
    "# books_html = bs4.BeautifulSoup(raw_books)\n",
    "# print(books_html)\n",
    "# [print(i) for i in ((raw_data))[\"historical\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf7384-6865-4558-b80c-ffd2bca53df9",
   "metadata": {},
   "source": [
    "## 1st cast df\n",
    "## 2nd use pd_date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b321744-1ae8-4d1c-ad75-4a9339a9092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_resp_df  = pd.DataFrame(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d86d3eb-f154-420f-966d-40f4ae528472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>historical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-08', 'open': 227.17, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-07', 'open': 224.63, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-06', 'open': 222.61, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-05', 'open': 221.8, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-04', 'open': 220.99, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-15', 'open': 65.92, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-14', 'open': 65.94, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-13', 'open': 65.28, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-12', 'open': 65.39, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-11', 'open': 64.58, 'high': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                                         historical\n",
       "0      AAPL  {'date': '2024-11-08', 'open': 227.17, 'high':...\n",
       "1      AAPL  {'date': '2024-11-07', 'open': 224.63, 'high':...\n",
       "2      AAPL  {'date': '2024-11-06', 'open': 222.61, 'high':...\n",
       "3      AAPL  {'date': '2024-11-05', 'open': 221.8, 'high': ...\n",
       "4      AAPL  {'date': '2024-11-04', 'open': 220.99, 'high':...\n",
       "...     ...                                                ...\n",
       "1253   AAPL  {'date': '2019-11-15', 'open': 65.92, 'high': ...\n",
       "1254   AAPL  {'date': '2019-11-14', 'open': 65.94, 'high': ...\n",
       "1255   AAPL  {'date': '2019-11-13', 'open': 65.28, 'high': ...\n",
       "1256   AAPL  {'date': '2019-11-12', 'open': 65.39, 'high': ...\n",
       "1257   AAPL  {'date': '2019-11-11', 'open': 64.58, 'high': ...\n",
       "\n",
       "[1258 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_resp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b83325-5973-4e3d-afd1-37cfa53a8bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76258cf8-6596-43dd-81ae-1efa3e43920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for _, row in finance_resp_df.iterrows():\n",
    "    historical_data = row['historical']\n",
    "    \n",
    "    # Extract the required information from the dictionary\n",
    "    date = historical_data['date']\n",
    "    open_price = historical_data['open']\n",
    "    high_price = historical_data['high']\n",
    "    low_price = historical_data['low']\n",
    "    \n",
    "    # Append the extracted data to the list\n",
    "    data_list.append({\n",
    "        'date': date,\n",
    "        'open': open_price,\n",
    "        'high': high_price,\n",
    "        'low': low_price\n",
    "    })\n",
    "second_half_df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e82c34d2-cb89-405a-a458-d8b860815187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>historical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-08', 'open': 227.17, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-07', 'open': 224.63, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-06', 'open': 222.61, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-05', 'open': 221.8, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2024-11-04', 'open': 220.99, 'high':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-15', 'open': 65.92, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-14', 'open': 65.94, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-13', 'open': 65.28, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-12', 'open': 65.39, 'high': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-11', 'open': 64.58, 'high': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                                         historical\n",
       "0      AAPL  {'date': '2024-11-08', 'open': 227.17, 'high':...\n",
       "1      AAPL  {'date': '2024-11-07', 'open': 224.63, 'high':...\n",
       "2      AAPL  {'date': '2024-11-06', 'open': 222.61, 'high':...\n",
       "3      AAPL  {'date': '2024-11-05', 'open': 221.8, 'high': ...\n",
       "4      AAPL  {'date': '2024-11-04', 'open': 220.99, 'high':...\n",
       "...     ...                                                ...\n",
       "1253   AAPL  {'date': '2019-11-15', 'open': 65.92, 'high': ...\n",
       "1254   AAPL  {'date': '2019-11-14', 'open': 65.94, 'high': ...\n",
       "1255   AAPL  {'date': '2019-11-13', 'open': 65.28, 'high': ...\n",
       "1256   AAPL  {'date': '2019-11-12', 'open': 65.39, 'high': ...\n",
       "1257   AAPL  {'date': '2019-11-11', 'open': 64.58, 'high': ...\n",
       "\n",
       "[1258 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_resp_df\n",
    "# finance_resp_df[\"historical\"][0]\n",
    "# pd.to_datetime(finance_resp_df[\"historical\"][0][\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00ac113a-3bd9-4494-a6f5-c442ac25f5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>227.17</td>\n",
       "      <td>228.66</td>\n",
       "      <td>226.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>224.63</td>\n",
       "      <td>227.88</td>\n",
       "      <td>224.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>222.61</td>\n",
       "      <td>226.07</td>\n",
       "      <td>221.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>221.80</td>\n",
       "      <td>223.95</td>\n",
       "      <td>221.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>220.99</td>\n",
       "      <td>222.79</td>\n",
       "      <td>219.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>65.92</td>\n",
       "      <td>66.44</td>\n",
       "      <td>65.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>65.94</td>\n",
       "      <td>66.22</td>\n",
       "      <td>65.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>65.28</td>\n",
       "      <td>66.19</td>\n",
       "      <td>65.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>65.39</td>\n",
       "      <td>65.70</td>\n",
       "      <td>65.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>64.58</td>\n",
       "      <td>65.62</td>\n",
       "      <td>64.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    open    high     low\n",
       "0     2024-11-08  227.17  228.66  226.41\n",
       "1     2024-11-07  224.63  227.88  224.57\n",
       "2     2024-11-06  222.61  226.07  221.19\n",
       "3     2024-11-05  221.80  223.95  221.14\n",
       "4     2024-11-04  220.99  222.79  219.71\n",
       "...          ...     ...     ...     ...\n",
       "1253  2019-11-15   65.92   66.44   65.75\n",
       "1254  2019-11-14   65.94   66.22   65.53\n",
       "1255  2019-11-13   65.28   66.19   65.27\n",
       "1256  2019-11-12   65.39   65.70   65.23\n",
       "1257  2019-11-11   64.58   65.62   64.57\n",
       "\n",
       "[1258 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_half_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c64cac-5d1c-4bc0-bbfe-0dccda71c1cd",
   "metadata": {},
   "source": [
    "## how to put df's directly next to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4944b4cf-b232-44de-b727-c1c65048efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df_n = pd.concat([finance_resp_df,second_half_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5e7f40f-e4b4-49c1-b0f1-090ba8342045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((fin_df_n[\"historical\"][0]).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258535c-0c13-4d9e-8ced-27a911ad57a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476d6da-a20f-4f40-8c21-1c5e27494d89",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e4a17-2012-4c5b-8253-636fe45790be",
   "metadata": {},
   "source": [
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8540e885-6081-4adf-ac25-184ad642dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?pd.date_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fa8ada6e-8f8d-4962-bca1-55df7b7f9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.date_range(\n",
    "    # start=pd.to_datetime(\"1/1/2018\").tz_localize(\"Europe/Berlin\"),\n",
    "    # end=pd.to_datetime(\"1/08/2018\").tz_localize(\"Europe/Berlin\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e9042cfa-2955-4d57-ac84-54242c139863",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df_n[\"date\"]  =pd.to_datetime(fin_df_n[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b8cdc17c-f88d-4011-8680-e3e526e2d17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2024-11-04\n",
       "1      2024-11-01\n",
       "2      2024-10-31\n",
       "3      2024-10-30\n",
       "4      2024-10-29\n",
       "          ...    \n",
       "1253   2019-11-11\n",
       "1254   2019-11-08\n",
       "1255   2019-11-07\n",
       "1256   2019-11-06\n",
       "1257   2019-11-05\n",
       "Name: date, Length: 1258, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df_n[\"date\"]\n",
    "#TERRRIFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9327c68a-c06a-4915-81e1-2868db6be230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-10-17 00:00:00')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df_n[\"date\"][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162585e3-ce7b-4891-b99c-5543d3e8b1d6",
   "metadata": {},
   "source": [
    "## how to have date_range broadcasted over [\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "11f006ad-8168-4d2d-b57c-4c669cffde19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2024-11-04\n",
       "1      2024-11-01\n",
       "2      2024-10-31\n",
       "3      2024-10-30\n",
       "4      2024-10-29\n",
       "          ...    \n",
       "1253   2019-11-11\n",
       "1254   2019-11-08\n",
       "1255   2019-11-07\n",
       "1256   2019-11-06\n",
       "1257   2019-11-05\n",
       "Name: date, Length: 1258, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df_n[\"date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45eefb0-b492-4ae5-85e0-67f7cc5f2413",
   "metadata": {},
   "source": [
    "have the generated objects be a \"mask\" for the results cleandf and have those all pulled where they match\n",
    "how to have the whole df entry return and does the mismatch in objects matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4d5a13b9-7235-4851-928e-082e0487913d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14',\n",
       "               '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18',\n",
       "               '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22',\n",
       "               '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26',\n",
       "               '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30',\n",
       "               '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04',\n",
       "               '2019-12-05', '2019-12-06', '2019-12-07'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how was I suppose to use date_range?\n",
    "\n",
    "\n",
    "# fin_df_n[fin_df_n['date'].dt.year == 2019]\n",
    "\n",
    "ex_mask = pd.date_range(start = \"2019-11-11\",end=\"2019-12-07\")\n",
    "ex_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36db868-2685-4d5d-993e-535c5b0b3e30",
   "metadata": {},
   "source": [
    "## MASK FOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9a645380-f548-41b2-86b7-d299241e1d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>historical</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-12-06', 'open': 66.87, 'high': ...</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>66.87</td>\n",
       "      <td>67.75</td>\n",
       "      <td>66.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-12-05', 'open': 65.95, 'high': ...</td>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>65.95</td>\n",
       "      <td>66.47</td>\n",
       "      <td>65.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-12-04', 'open': 65.27, 'high': ...</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>65.27</td>\n",
       "      <td>65.83</td>\n",
       "      <td>65.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-12-03', 'open': 64.58, 'high': ...</td>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>64.58</td>\n",
       "      <td>64.88</td>\n",
       "      <td>64.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-12-02', 'open': 66.82, 'high': ...</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>66.82</td>\n",
       "      <td>67.06</td>\n",
       "      <td>65.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-29', 'open': 66.65, 'high': ...</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>66.65</td>\n",
       "      <td>67.00</td>\n",
       "      <td>66.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-27', 'open': 66.4, 'high': 6...</td>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>66.40</td>\n",
       "      <td>67.00</td>\n",
       "      <td>66.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-26', 'open': 66.74, 'high': ...</td>\n",
       "      <td>2019-11-26</td>\n",
       "      <td>66.74</td>\n",
       "      <td>66.79</td>\n",
       "      <td>65.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-25', 'open': 65.68, 'high': ...</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>65.68</td>\n",
       "      <td>66.61</td>\n",
       "      <td>65.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-22', 'open': 65.65, 'high': ...</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>65.65</td>\n",
       "      <td>65.80</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-21', 'open': 65.92, 'high': ...</td>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>65.92</td>\n",
       "      <td>66.00</td>\n",
       "      <td>65.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-20', 'open': 66.39, 'high': ...</td>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>66.39</td>\n",
       "      <td>66.52</td>\n",
       "      <td>65.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-19', 'open': 66.97, 'high': ...</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>66.97</td>\n",
       "      <td>67.00</td>\n",
       "      <td>66.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-18', 'open': 66.45, 'high': ...</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>66.45</td>\n",
       "      <td>66.86</td>\n",
       "      <td>66.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-15', 'open': 65.92, 'high': ...</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>65.92</td>\n",
       "      <td>66.44</td>\n",
       "      <td>65.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-14', 'open': 65.94, 'high': ...</td>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>65.94</td>\n",
       "      <td>66.22</td>\n",
       "      <td>65.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-13', 'open': 65.28, 'high': ...</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>65.28</td>\n",
       "      <td>66.19</td>\n",
       "      <td>65.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-12', 'open': 65.39, 'high': ...</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>65.39</td>\n",
       "      <td>65.70</td>\n",
       "      <td>65.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>{'date': '2019-11-11', 'open': 64.58, 'high': ...</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>64.58</td>\n",
       "      <td>65.62</td>\n",
       "      <td>64.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                                         historical       date  \\\n",
       "1235   AAPL  {'date': '2019-12-06', 'open': 66.87, 'high': ... 2019-12-06   \n",
       "1236   AAPL  {'date': '2019-12-05', 'open': 65.95, 'high': ... 2019-12-05   \n",
       "1237   AAPL  {'date': '2019-12-04', 'open': 65.27, 'high': ... 2019-12-04   \n",
       "1238   AAPL  {'date': '2019-12-03', 'open': 64.58, 'high': ... 2019-12-03   \n",
       "1239   AAPL  {'date': '2019-12-02', 'open': 66.82, 'high': ... 2019-12-02   \n",
       "1240   AAPL  {'date': '2019-11-29', 'open': 66.65, 'high': ... 2019-11-29   \n",
       "1241   AAPL  {'date': '2019-11-27', 'open': 66.4, 'high': 6... 2019-11-27   \n",
       "1242   AAPL  {'date': '2019-11-26', 'open': 66.74, 'high': ... 2019-11-26   \n",
       "1243   AAPL  {'date': '2019-11-25', 'open': 65.68, 'high': ... 2019-11-25   \n",
       "1244   AAPL  {'date': '2019-11-22', 'open': 65.65, 'high': ... 2019-11-22   \n",
       "1245   AAPL  {'date': '2019-11-21', 'open': 65.92, 'high': ... 2019-11-21   \n",
       "1246   AAPL  {'date': '2019-11-20', 'open': 66.39, 'high': ... 2019-11-20   \n",
       "1247   AAPL  {'date': '2019-11-19', 'open': 66.97, 'high': ... 2019-11-19   \n",
       "1248   AAPL  {'date': '2019-11-18', 'open': 66.45, 'high': ... 2019-11-18   \n",
       "1249   AAPL  {'date': '2019-11-15', 'open': 65.92, 'high': ... 2019-11-15   \n",
       "1250   AAPL  {'date': '2019-11-14', 'open': 65.94, 'high': ... 2019-11-14   \n",
       "1251   AAPL  {'date': '2019-11-13', 'open': 65.28, 'high': ... 2019-11-13   \n",
       "1252   AAPL  {'date': '2019-11-12', 'open': 65.39, 'high': ... 2019-11-12   \n",
       "1253   AAPL  {'date': '2019-11-11', 'open': 64.58, 'high': ... 2019-11-11   \n",
       "\n",
       "       open   high    low  \n",
       "1235  66.87  67.75  66.83  \n",
       "1236  65.95  66.47  65.68  \n",
       "1237  65.27  65.83  65.17  \n",
       "1238  64.58  64.88  64.07  \n",
       "1239  66.82  67.06  65.86  \n",
       "1240  66.65  67.00  66.47  \n",
       "1241  66.40  67.00  66.33  \n",
       "1242  66.74  66.79  65.63  \n",
       "1243  65.68  66.61  65.63  \n",
       "1244  65.65  65.80  65.21  \n",
       "1245  65.92  66.00  65.30  \n",
       "1246  66.39  66.52  65.10  \n",
       "1247  66.97  67.00  66.35  \n",
       "1248  66.45  66.86  66.06  \n",
       "1249  65.92  66.44  65.75  \n",
       "1250  65.94  66.22  65.53  \n",
       "1251  65.28  66.19  65.27  \n",
       "1252  65.39  65.70  65.23  \n",
       "1253  64.58  65.62  64.57  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df_n.loc[fin_df_n[\"date\"].isin(ex_mask)]\n",
    "#YURRRR-eka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1be9fe-251c-469e-93c3-d886bdae88aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931eba6f-4e11-4667-b034-1304e7e9b033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f56c6bb-24c2-4a89-a2c5-088ac2ee2462",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8c7ba-3d84-4e0e-a0a6-5b3e7e1f94b5",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bbe73-d002-43ec-8744-ce99d815b32e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd404d88-022d-451c-b591-24c56db9df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "\n",
    "def stock_history(args,year,month):\n",
    "    \"\"\"\n",
    "    \n",
    "    year : \n",
    "        what year the month is gonna be in\n",
    "    month\n",
    "        the entirety of the month\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    # return str(arg)\n",
    "    # company_url = str(TCR)\n",
    "    # return company_url\n",
    "\n",
    "    finance_model_url = 'https://financialmodelingprep.com/api/v3/historical-price-full/'\n",
    "    \n",
    "    ticker_url = finance_model_url + args\n",
    "\n",
    "    resp_TCR = requests.get(ticker_url+\"?apikey=TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\")\n",
    "\n",
    "    finance_dirty_df =  pd.DataFrame(resp_TCR.json())\n",
    "    \n",
    "    data_list = []\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for _, row in finance_dirty_df.iterrows():\n",
    "        historical_data = row['historical']\n",
    "        \n",
    "        # Extract the required information from the dictionary\n",
    "        date = historical_data['date']\n",
    "        open_price = historical_data['open']\n",
    "        high_price = historical_data['high']\n",
    "        low_price = historical_data['low']\n",
    "        \n",
    "        # Append the extracted data to the list\n",
    "        data_list.append({\n",
    "            'date': date,\n",
    "            'open': open_price,\n",
    "            'high': high_price,\n",
    "            'low': low_price\n",
    "        })\n",
    "    second_half_df = pd.DataFrame(data_list)\n",
    "    \n",
    "    \n",
    "    finance_clean_df = pd.concat([finance_dirty_df,second_half_df],axis=1)\n",
    "    \n",
    "    finance_clean_df[\"date\"]  =pd.to_datetime(finance_clean_df[\"date\"])\n",
    "\n",
    "\n",
    "    # mask = (finance_clean_df['date'].dt.year == year) & (finance_clean_df['date'].dt.month == month)\n",
    "    # why is this returning the whole copy of the df\n",
    "\n",
    "    # how to cast the year and month to into a string\n",
    "    # mask = pd.date_range(start = '\"year,month\"',end='\"year,month + 1\"',)\n",
    "    \n",
    "    # return finance_clean_df.loc[finance_clean_df[\"date\"].isin(mask)]\n",
    "\n",
    "\n",
    "    _, days_in_month = calendar.monthrange(year, month)\n",
    "    \n",
    "    # Create date range for the specified year and month\n",
    "    start_date = pd.Timestamp(year=year, month=month, day=1)\n",
    "    end_date = pd.Timestamp(year=year, month=month, day=days_in_month)\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    # Filter using isin with the date range\n",
    "    filtered_df = finance_clean_df[finance_clean_df[\"date\"].isin(date_range)]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00c3b4f0-cc17-43bb-adcd-51e42426c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Fetches the historical stock data for a given ticker symbol, year, and month.\n",
    "    \n",
    "    Parameters:\n",
    "    ticker (str): The stock ticker symbol.\n",
    "    year (int): The year of the data to fetch.\n",
    "    month (int): The month of the data to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing stock data for the specified month.\n",
    "    \"\"\"\n",
    "    # Define the API key and dates for the range\n",
    "    api_key = \"TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\"  # Replace with your actual API key\n",
    "    start_date = f\"{year}-{month:02d}-01\"\n",
    "    end_date = f\"{year}-{month + 1:02d}-01\" if month < 12 else f\"{year + 1}-01-01\"\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={api_key}&from={start_date}&to={end_date}'\n",
    "    \n",
    "    # Debug: Print the URL to verify its format\n",
    "    print(\"Request URL:\", url)\n",
    "    \n",
    "    # Make the API request and retrieve data as JSON\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if 'historical' data is available in the response\n",
    "    if 'historical' not in data:\n",
    "        print(\"No historical data found for this ticker and date range.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data found\n",
    "    \n",
    "    # Convert the 'historical' data to a DataFrame without filtering\n",
    "    df = pd.DataFrame(data['historical'])\n",
    "    \n",
    "    # Convert the 'date' column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89f79622-1503-4534-988c-7a3342538083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request URL: https://financialmodelingprep.com/api/v3/historical-price-full/BYND?apikey=TEj6e6njs900yG5LGYcwWxdKNdpE8oN0&from=2019-06-01&to=2019-07-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>161.49</td>\n",
       "      <td>162.45</td>\n",
       "      <td>152.0000</td>\n",
       "      <td>152.58</td>\n",
       "      <td>152.580002</td>\n",
       "      <td>4449296</td>\n",
       "      <td>4438900</td>\n",
       "      <td>-8.91</td>\n",
       "      <td>-5.52000</td>\n",
       "      <td>155.44</td>\n",
       "      <td>July 01, 19</td>\n",
       "      <td>-0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>165.30</td>\n",
       "      <td>168.80</td>\n",
       "      <td>159.5500</td>\n",
       "      <td>160.68</td>\n",
       "      <td>160.679993</td>\n",
       "      <td>7315297</td>\n",
       "      <td>7315300</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-2.79000</td>\n",
       "      <td>163.92</td>\n",
       "      <td>June 28, 19</td>\n",
       "      <td>-0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>157.31</td>\n",
       "      <td>164.79</td>\n",
       "      <td>155.4500</td>\n",
       "      <td>162.91</td>\n",
       "      <td>162.910004</td>\n",
       "      <td>5719421</td>\n",
       "      <td>5731400</td>\n",
       "      <td>5.60</td>\n",
       "      <td>3.56000</td>\n",
       "      <td>160.43</td>\n",
       "      <td>June 27, 19</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>160.10</td>\n",
       "      <td>162.25</td>\n",
       "      <td>153.0200</td>\n",
       "      <td>160.48</td>\n",
       "      <td>160.479996</td>\n",
       "      <td>6378629</td>\n",
       "      <td>6378600</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23735</td>\n",
       "      <td>157.99</td>\n",
       "      <td>June 26, 19</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>138.50</td>\n",
       "      <td>150.69</td>\n",
       "      <td>138.3425</td>\n",
       "      <td>150.60</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>6682929</td>\n",
       "      <td>6632500</td>\n",
       "      <td>12.10</td>\n",
       "      <td>8.74000</td>\n",
       "      <td>146.35</td>\n",
       "      <td>June 25, 19</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>151.88</td>\n",
       "      <td>152.70</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>140.99</td>\n",
       "      <td>140.990005</td>\n",
       "      <td>6538497</td>\n",
       "      <td>6538500</td>\n",
       "      <td>-10.89</td>\n",
       "      <td>-7.17000</td>\n",
       "      <td>142.69</td>\n",
       "      <td>June 24, 19</td>\n",
       "      <td>-0.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>153.54</td>\n",
       "      <td>161.79</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>154.13</td>\n",
       "      <td>154.130005</td>\n",
       "      <td>7474586</td>\n",
       "      <td>7474600</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.38426</td>\n",
       "      <td>155.01</td>\n",
       "      <td>June 21, 19</td>\n",
       "      <td>0.003843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>173.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>163.3000</td>\n",
       "      <td>165.17</td>\n",
       "      <td>165.169998</td>\n",
       "      <td>6660492</td>\n",
       "      <td>6660500</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>-4.53000</td>\n",
       "      <td>167.58</td>\n",
       "      <td>June 20, 19</td>\n",
       "      <td>-0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>171.37</td>\n",
       "      <td>174.45</td>\n",
       "      <td>162.2500</td>\n",
       "      <td>169.28</td>\n",
       "      <td>169.279999</td>\n",
       "      <td>9451961</td>\n",
       "      <td>9452000</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.22000</td>\n",
       "      <td>167.61</td>\n",
       "      <td>June 19, 19</td>\n",
       "      <td>-0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>200.00</td>\n",
       "      <td>201.88</td>\n",
       "      <td>160.7000</td>\n",
       "      <td>169.89</td>\n",
       "      <td>169.889999</td>\n",
       "      <td>23966910</td>\n",
       "      <td>23966900</td>\n",
       "      <td>-30.11</td>\n",
       "      <td>-15.06000</td>\n",
       "      <td>175.95</td>\n",
       "      <td>June 18, 19</td>\n",
       "      <td>-0.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>163.18</td>\n",
       "      <td>171.19</td>\n",
       "      <td>160.6111</td>\n",
       "      <td>169.96</td>\n",
       "      <td>169.960007</td>\n",
       "      <td>14626683</td>\n",
       "      <td>14626700</td>\n",
       "      <td>6.78</td>\n",
       "      <td>4.15000</td>\n",
       "      <td>166.83</td>\n",
       "      <td>June 17, 19</td>\n",
       "      <td>0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>142.01</td>\n",
       "      <td>157.90</td>\n",
       "      <td>141.8000</td>\n",
       "      <td>151.48</td>\n",
       "      <td>151.479996</td>\n",
       "      <td>14964553</td>\n",
       "      <td>14964600</td>\n",
       "      <td>9.47</td>\n",
       "      <td>6.67000</td>\n",
       "      <td>151.75</td>\n",
       "      <td>June 14, 19</td>\n",
       "      <td>0.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>141.52</td>\n",
       "      <td>146.45</td>\n",
       "      <td>134.2500</td>\n",
       "      <td>141.39</td>\n",
       "      <td>141.389999</td>\n",
       "      <td>9474562</td>\n",
       "      <td>9474600</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.09186</td>\n",
       "      <td>141.31</td>\n",
       "      <td>June 13, 19</td>\n",
       "      <td>-0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>133.99</td>\n",
       "      <td>150.45</td>\n",
       "      <td>131.5632</td>\n",
       "      <td>141.97</td>\n",
       "      <td>141.970001</td>\n",
       "      <td>16900631</td>\n",
       "      <td>16918600</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.96000</td>\n",
       "      <td>140.38</td>\n",
       "      <td>June 12, 19</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>145.25</td>\n",
       "      <td>150.00</td>\n",
       "      <td>125.2300</td>\n",
       "      <td>126.04</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>15515979</td>\n",
       "      <td>15516000</td>\n",
       "      <td>-19.21</td>\n",
       "      <td>-13.23000</td>\n",
       "      <td>136.34</td>\n",
       "      <td>June 11, 19</td>\n",
       "      <td>-0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>155.70</td>\n",
       "      <td>186.43</td>\n",
       "      <td>147.0000</td>\n",
       "      <td>168.10</td>\n",
       "      <td>168.100006</td>\n",
       "      <td>24978735</td>\n",
       "      <td>24986000</td>\n",
       "      <td>12.40</td>\n",
       "      <td>7.96000</td>\n",
       "      <td>167.94</td>\n",
       "      <td>June 10, 19</td>\n",
       "      <td>0.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>130.00</td>\n",
       "      <td>149.46</td>\n",
       "      <td>120.7600</td>\n",
       "      <td>138.65</td>\n",
       "      <td>138.649994</td>\n",
       "      <td>23916747</td>\n",
       "      <td>23916700</td>\n",
       "      <td>8.65</td>\n",
       "      <td>6.65000</td>\n",
       "      <td>132.62</td>\n",
       "      <td>June 07, 19</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>102.00</td>\n",
       "      <td>102.25</td>\n",
       "      <td>98.8500</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>6483991</td>\n",
       "      <td>6484000</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-2.45000</td>\n",
       "      <td>100.65</td>\n",
       "      <td>June 06, 19</td>\n",
       "      <td>-0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.50</td>\n",
       "      <td>99.6400</td>\n",
       "      <td>102.60</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>4283474</td>\n",
       "      <td>4283500</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>-2.75000</td>\n",
       "      <td>102.18</td>\n",
       "      <td>June 05, 19</td>\n",
       "      <td>-0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>101.25</td>\n",
       "      <td>103.50</td>\n",
       "      <td>97.8200</td>\n",
       "      <td>103.41</td>\n",
       "      <td>103.410004</td>\n",
       "      <td>5484873</td>\n",
       "      <td>5484900</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.13000</td>\n",
       "      <td>100.64</td>\n",
       "      <td>June 04, 19</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>104.14</td>\n",
       "      <td>108.67</td>\n",
       "      <td>95.6620</td>\n",
       "      <td>96.16</td>\n",
       "      <td>96.160004</td>\n",
       "      <td>8027710</td>\n",
       "      <td>8027700</td>\n",
       "      <td>-7.98</td>\n",
       "      <td>-7.66000</td>\n",
       "      <td>103.12</td>\n",
       "      <td>June 03, 19</td>\n",
       "      <td>-0.076600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high       low   close    adjClose    volume  \\\n",
       "0  2019-07-01  161.49  162.45  152.0000  152.58  152.580002   4449296   \n",
       "1  2019-06-28  165.30  168.80  159.5500  160.68  160.679993   7315297   \n",
       "2  2019-06-27  157.31  164.79  155.4500  162.91  162.910004   5719421   \n",
       "3  2019-06-26  160.10  162.25  153.0200  160.48  160.479996   6378629   \n",
       "4  2019-06-25  138.50  150.69  138.3425  150.60  150.600006   6682929   \n",
       "5  2019-06-24  151.88  152.70  138.0000  140.99  140.990005   6538497   \n",
       "6  2019-06-21  153.54  161.79  150.0000  154.13  154.130005   7474586   \n",
       "7  2019-06-20  173.00  174.00  163.3000  165.17  165.169998   6660492   \n",
       "8  2019-06-19  171.37  174.45  162.2500  169.28  169.279999   9451961   \n",
       "9  2019-06-18  200.00  201.88  160.7000  169.89  169.889999  23966910   \n",
       "10 2019-06-17  163.18  171.19  160.6111  169.96  169.960007  14626683   \n",
       "11 2019-06-14  142.01  157.90  141.8000  151.48  151.479996  14964553   \n",
       "12 2019-06-13  141.52  146.45  134.2500  141.39  141.389999   9474562   \n",
       "13 2019-06-12  133.99  150.45  131.5632  141.97  141.970001  16900631   \n",
       "14 2019-06-11  145.25  150.00  125.2300  126.04  126.040001  15515979   \n",
       "15 2019-06-10  155.70  186.43  147.0000  168.10  168.100006  24978735   \n",
       "16 2019-06-07  130.00  149.46  120.7600  138.65  138.649994  23916747   \n",
       "17 2019-06-06  102.00  102.25   98.8500   99.50   99.500000   6483991   \n",
       "18 2019-06-05  105.50  105.50   99.6400  102.60  102.599998   4283474   \n",
       "19 2019-06-04  101.25  103.50   97.8200  103.41  103.410004   5484873   \n",
       "20 2019-06-03  104.14  108.67   95.6620   96.16   96.160004   8027710   \n",
       "\n",
       "    unadjustedVolume  change  changePercent    vwap        label  \\\n",
       "0            4438900   -8.91       -5.52000  155.44  July 01, 19   \n",
       "1            7315300   -4.62       -2.79000  163.92  June 28, 19   \n",
       "2            5731400    5.60        3.56000  160.43  June 27, 19   \n",
       "3            6378600    0.38        0.23735  157.99  June 26, 19   \n",
       "4            6632500   12.10        8.74000  146.35  June 25, 19   \n",
       "5            6538500  -10.89       -7.17000  142.69  June 24, 19   \n",
       "6            7474600    0.59        0.38426  155.01  June 21, 19   \n",
       "7            6660500   -7.83       -4.53000  167.58  June 20, 19   \n",
       "8            9452000   -2.09       -1.22000  167.61  June 19, 19   \n",
       "9           23966900  -30.11      -15.06000  175.95  June 18, 19   \n",
       "10          14626700    6.78        4.15000  166.83  June 17, 19   \n",
       "11          14964600    9.47        6.67000  151.75  June 14, 19   \n",
       "12           9474600   -0.13       -0.09186  141.31  June 13, 19   \n",
       "13          16918600    7.98        5.96000  140.38  June 12, 19   \n",
       "14          15516000  -19.21      -13.23000  136.34  June 11, 19   \n",
       "15          24986000   12.40        7.96000  167.94  June 10, 19   \n",
       "16          23916700    8.65        6.65000  132.62  June 07, 19   \n",
       "17           6484000   -2.50       -2.45000  100.65  June 06, 19   \n",
       "18           4283500   -2.90       -2.75000  102.18  June 05, 19   \n",
       "19           5484900    2.16        2.13000  100.64  June 04, 19   \n",
       "20           8027700   -7.98       -7.66000  103.12  June 03, 19   \n",
       "\n",
       "    changeOverTime  \n",
       "0        -0.055200  \n",
       "1        -0.027900  \n",
       "2         0.035600  \n",
       "3         0.002374  \n",
       "4         0.087400  \n",
       "5        -0.071700  \n",
       "6         0.003843  \n",
       "7        -0.045300  \n",
       "8        -0.012200  \n",
       "9        -0.150600  \n",
       "10        0.041500  \n",
       "11        0.066700  \n",
       "12       -0.000919  \n",
       "13        0.059600  \n",
       "14       -0.132300  \n",
       "15        0.079600  \n",
       "16        0.066500  \n",
       "17       -0.024500  \n",
       "18       -0.027500  \n",
       "19        0.021300  \n",
       "20       -0.076600  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_history(\"BYND\",2019\n",
    "              ,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2a974ca2-7651-4469-b5ae-580f588ccd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2024-11-04\n",
       "1      2024-11-01\n",
       "2      2024-10-31\n",
       "3      2024-10-30\n",
       "4      2024-10-29\n",
       "          ...    \n",
       "1253   2019-11-11\n",
       "1254   2019-11-08\n",
       "1255   2019-11-07\n",
       "1256   2019-11-06\n",
       "1257   2019-11-05\n",
       "Name: date, Length: 1258, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e6d9d282-7132-4fda-b020-78aef098e673",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1445332345.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[189], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def stock_stats(stock_history_df):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "           cc\n",
    "               ,ccO=-\n",
    "           cc  | cc\n",
    "         -=Occ | ;\n",
    "           cc\\ |/ cc \n",
    "              \\|,ccO=-\n",
    "            ;=.|| cc\n",
    "            __|||,-.\n",
    "           `._\\ -.__\\\n",
    "              |/\n",
    "             ,||.\n",
    "             |--|\n",
    "             |  |\n",
    "             |  |\n",
    "     jrei    |  |   \n",
    "            /    \\\n",
    "          ,'      `.\n",
    "         (          )\n",
    "          `-.____.-'\n",
    "\n",
    "    VASE for volume the actual sales are still contained in the json history \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # delta-price is str \n",
    "    # volume is str \n",
    "\n",
    "    # delta price is literally just a subtraction open_0 - open_t\n",
    "\n",
    "    # volume is high and low averaged DAILY * the len(shares_(t_i))\n",
    "        # t_i like shares sold in day_k in the subset created from stock_history\n",
    "\n",
    "    # TODO\n",
    "        # extract from historcal the volume for the entry will it match to my dates?\n",
    "    # B(billions) for  transaction volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45ed9e2f-0346-4ad0-bd03-cce2b986237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Fetches the historical stock data for a given ticker symbol, year, and month.\n",
    "    \n",
    "    Parameters:\n",
    "    ticker (str): The stock ticker symbol.\n",
    "    year (int): The year of the data to fetch.\n",
    "    month (int): The month of the data to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing stock data for the specified month.\n",
    "    \"\"\"\n",
    "    # Define the API URL\n",
    "    api_key = \"TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\"  # Replace with your actual API key\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={api_key}'\n",
    "    \n",
    "    # Make the API request and retrieve data as JSON\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Convert the 'historical' data to a DataFrame\n",
    "    if 'historical' in data:\n",
    "        df = pd.DataFrame(data['historical'])\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data found\n",
    "    \n",
    "    # Convert date column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Filter data for the specified month and year\n",
    "    mask = (df['date'].dt.year == year) & (df['date'].dt.month == month)\n",
    "    filtered_df = df.loc[mask]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e6297-4474-46a3-b307-4ee482b6cc62",
   "metadata": {},
   "source": [
    "## <mark> WHHYY ISNT THE TST BYND WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f05978a0-0d7f-4038-b2f3-e8521c0a16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Fetches the historical stock data for a given ticker symbol, year, and month.\n",
    "    \n",
    "    Parameters:\n",
    "    ticker (str): The stock ticker symbol.\n",
    "    year (int): The year of the data to fetch.\n",
    "    month (int): The month of the data to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing stock data for the specified month.\n",
    "    \"\"\"\n",
    "    # Define the API URL with from and to date parameters\n",
    "    api_key = \"TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\"  # Replace with your actual API key\n",
    "    start_date = f\"{year}-{month:02d}-01\"\n",
    "    end_date = f\"{year}-{month + 1:02d}-01\" if month < 12 else f\"{year + 1}-01-01\"\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={api_key}&from={start_date}&to={end_date}'\n",
    "    \n",
    "    # Make the API request and retrieve data as JSON\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if 'historical' data is available in the response\n",
    "    if 'historical' not in data:\n",
    "        print(\"No historical data found for this ticker.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data found\n",
    "    \n",
    "    # Convert the 'historical' data to a DataFrame\n",
    "    df = pd.DataFrame(data['historical'])\n",
    "    \n",
    "    # Convert the 'date' column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a670e5-426f-4676-aee1-175dfedae38b",
   "metadata": {},
   "source": [
    "<h1><mark>Now it doesn't work with appl :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea34a650-78d7-47c6-a48a-a88acee43f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Fetches the historical stock data for a given ticker symbol, year, and month.\n",
    "    \n",
    "    Parameters:\n",
    "    ticker (str): The stock ticker symbol.\n",
    "    year (int): The year of the data to fetch.\n",
    "    month (int): The month of the data to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing stock data for the specified month.\n",
    "    \"\"\"\n",
    "    # Define the API key and dates for the range\n",
    "    api_key = \"TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\"  # Replace with your actual API key\n",
    "    start_date = f\"{year}-{month:02d}-01\"\n",
    "    end_date = f\"{year}-{month + 1:02d}-01\" if month < 12 else f\"{year + 1}-01-01\"\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={api_key}&from={start_date}&to={end_date}'\n",
    "    \n",
    "    # Debug: Print the URL to verify its format\n",
    "    # print(\"Request URL:\", url)\n",
    "    \n",
    "    # Make the API request and retrieve data as JSON\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if 'historical' data is available in the response\n",
    "    if 'historical' not in data:\n",
    "        print(\"No historical data found for this ticker and date range.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data found\n",
    "    \n",
    "    # Convert the 'historical' data to a DataFrame without filtering\n",
    "    df = pd.DataFrame(data['historical'])\n",
    "    \n",
    "    # Convert the 'date' column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "076eac1a-66a5-4321-bafb-7587fc23f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Fetches the historical stock data for a given ticker symbol, year, and month.\n",
    "    \n",
    "    Parameters:\n",
    "    ticker (str): The stock ticker symbol.\n",
    "    year (int): The year of the data to fetch.\n",
    "    month (int): The month of the data to fetch.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing stock data for the specified month.\n",
    "    \"\"\"\n",
    "    # Define the API key and dates for the range\n",
    "    api_key = \"TEj6e6njs900yG5LGYcwWxdKNdpE8oN0\"  # Replace with your actual API key\n",
    "    start_date = f\"{year}-{month:02d}-01\"\n",
    "    end_date = f\"{year}-{month + 1:02d}-01\" if month < 12 else f\"{year + 1}-01-01\"\n",
    "    url = f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={api_key}&from={start_date}&to={end_date}'\n",
    "    \n",
    "    # Make the API request and retrieve data as JSON\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if 'historical' data is available in the response\n",
    "    if 'historical' not in data:\n",
    "        print(\"No historical data found for this ticker and date range.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no data found\n",
    "    \n",
    "    # Convert the 'historical' data to a DataFrame without filtering\n",
    "    df = pd.DataFrame(data['historical'])\n",
    "    \n",
    "    # Convert the 'date' column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Filter to include only rows that match the specified year and month\n",
    "    df = df[(df['date'].dt.year == year) & (df['date'].dt.month == month)]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f41d6fa-70d2-4cac-8d42-c4b259385f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_history(\"F\",2022,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a5efeff-7a39-4cad-bd5a-63ec7eb9c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(df):\n",
    "    \"\"\"\n",
    "    Calculates the percent change and total transaction volume for the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing stock data for a specific month.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing (percent change, total transaction volume) as strings.\n",
    "    \"\"\"\n",
    "    # Ensure the DataFrame has the necessary data\n",
    "    if df.empty or 'open' not in df.columns or 'close' not in df.columns:\n",
    "        return (\"N/A\", \"N/A\")\n",
    "    \n",
    "    # Sort the DataFrame by date to get the first and last records\n",
    "    df = df.sort_values(by='date')\n",
    "    \n",
    "    # Calculate percent change\n",
    "    start_price = df.iloc[0]['open']\n",
    "    end_price = df.iloc[-1]['close']\n",
    "    percent_change = ((end_price - start_price) / start_price) * 100\n",
    "    percent_change_str = f\"{percent_change:+.2f}%\"\n",
    "    \n",
    "    # Calculate total transaction volume\n",
    "    total_volume = 0\n",
    "    for _, row in df.iterrows():\n",
    "        avg_price = (row['high'] + row['low']) / 2  # Midpoint of high and low\n",
    "        volume = row['volume']\n",
    "        total_volume += avg_price * volume  # Transaction volume for the day\n",
    "    \n",
    "    # Convert to billions and format as a string\n",
    "    total_volume_billion = total_volume / 1e9\n",
    "    total_volume_str = f\"{total_volume_billion:.2f}B\"\n",
    "    \n",
    "    return percent_change_str, total_volume_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2658a4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>104.5500</td>\n",
       "      <td>97.2600</td>\n",
       "      <td>104.12</td>\n",
       "      <td>104.120003</td>\n",
       "      <td>7733863</td>\n",
       "      <td>7733900</td>\n",
       "      <td>4.1200</td>\n",
       "      <td>4.12000</td>\n",
       "      <td>100.85</td>\n",
       "      <td>May 31, 19</td>\n",
       "      <td>0.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>101.8965</td>\n",
       "      <td>105.2500</td>\n",
       "      <td>94.0300</td>\n",
       "      <td>98.59</td>\n",
       "      <td>98.589996</td>\n",
       "      <td>12359807</td>\n",
       "      <td>12359800</td>\n",
       "      <td>-3.3065</td>\n",
       "      <td>-3.24000</td>\n",
       "      <td>99.98</td>\n",
       "      <td>May 30, 19</td>\n",
       "      <td>-0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>90.0500</td>\n",
       "      <td>97.6500</td>\n",
       "      <td>87.3200</td>\n",
       "      <td>97.50</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>8371994</td>\n",
       "      <td>8372000</td>\n",
       "      <td>7.4500</td>\n",
       "      <td>8.27000</td>\n",
       "      <td>92.27</td>\n",
       "      <td>May 29, 19</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>83.9800</td>\n",
       "      <td>88.8300</td>\n",
       "      <td>83.7000</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>6604012</td>\n",
       "      <td>6604000</td>\n",
       "      <td>2.0200</td>\n",
       "      <td>2.41000</td>\n",
       "      <td>86.20</td>\n",
       "      <td>May 28, 19</td>\n",
       "      <td>0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>83.9200</td>\n",
       "      <td>85.5000</td>\n",
       "      <td>79.5100</td>\n",
       "      <td>79.67</td>\n",
       "      <td>79.669998</td>\n",
       "      <td>2909494</td>\n",
       "      <td>2909500</td>\n",
       "      <td>-4.2500</td>\n",
       "      <td>-5.06000</td>\n",
       "      <td>82.81</td>\n",
       "      <td>May 24, 19</td>\n",
       "      <td>-0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>79.4000</td>\n",
       "      <td>83.8000</td>\n",
       "      <td>78.1227</td>\n",
       "      <td>82.10</td>\n",
       "      <td>82.099998</td>\n",
       "      <td>4331336</td>\n",
       "      <td>4331300</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>3.40000</td>\n",
       "      <td>80.97</td>\n",
       "      <td>May 23, 19</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>77.3800</td>\n",
       "      <td>81.7400</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>77.63</td>\n",
       "      <td>77.629997</td>\n",
       "      <td>3898382</td>\n",
       "      <td>3898400</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.32308</td>\n",
       "      <td>79.49</td>\n",
       "      <td>May 22, 19</td>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>88.0300</td>\n",
       "      <td>88.7500</td>\n",
       "      <td>76.7600</td>\n",
       "      <td>77.50</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>9065090</td>\n",
       "      <td>9065100</td>\n",
       "      <td>-10.5300</td>\n",
       "      <td>-11.96000</td>\n",
       "      <td>80.23</td>\n",
       "      <td>May 21, 19</td>\n",
       "      <td>-0.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>88.9000</td>\n",
       "      <td>90.9600</td>\n",
       "      <td>83.1300</td>\n",
       "      <td>86.09</td>\n",
       "      <td>86.089996</td>\n",
       "      <td>5189713</td>\n",
       "      <td>5189700</td>\n",
       "      <td>-2.8100</td>\n",
       "      <td>-3.16000</td>\n",
       "      <td>87.66</td>\n",
       "      <td>May 20, 19</td>\n",
       "      <td>-0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>92.4600</td>\n",
       "      <td>96.6800</td>\n",
       "      <td>85.7100</td>\n",
       "      <td>89.35</td>\n",
       "      <td>89.349998</td>\n",
       "      <td>10718760</td>\n",
       "      <td>10724100</td>\n",
       "      <td>-3.1100</td>\n",
       "      <td>-3.36000</td>\n",
       "      <td>90.67</td>\n",
       "      <td>May 17, 19</td>\n",
       "      <td>-0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>90.1000</td>\n",
       "      <td>96.7845</td>\n",
       "      <td>89.5100</td>\n",
       "      <td>92.92</td>\n",
       "      <td>92.919998</td>\n",
       "      <td>13900335</td>\n",
       "      <td>13900300</td>\n",
       "      <td>2.8200</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>92.52</td>\n",
       "      <td>May 16, 19</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>79.0000</td>\n",
       "      <td>93.0000</td>\n",
       "      <td>74.5500</td>\n",
       "      <td>86.92</td>\n",
       "      <td>86.919998</td>\n",
       "      <td>18356209</td>\n",
       "      <td>18356200</td>\n",
       "      <td>7.9200</td>\n",
       "      <td>10.03000</td>\n",
       "      <td>85.89</td>\n",
       "      <td>May 15, 19</td>\n",
       "      <td>0.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>72.4800</td>\n",
       "      <td>80.7500</td>\n",
       "      <td>71.1200</td>\n",
       "      <td>79.68</td>\n",
       "      <td>79.680000</td>\n",
       "      <td>7079600</td>\n",
       "      <td>7079600</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>9.93000</td>\n",
       "      <td>76.63</td>\n",
       "      <td>May 14, 19</td>\n",
       "      <td>0.099300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-05-13</td>\n",
       "      <td>65.4600</td>\n",
       "      <td>71.9600</td>\n",
       "      <td>63.3600</td>\n",
       "      <td>69.50</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>4784517</td>\n",
       "      <td>4784500</td>\n",
       "      <td>4.0400</td>\n",
       "      <td>6.17000</td>\n",
       "      <td>68.91</td>\n",
       "      <td>May 13, 19</td>\n",
       "      <td>0.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>69.0900</td>\n",
       "      <td>69.3323</td>\n",
       "      <td>61.6000</td>\n",
       "      <td>66.22</td>\n",
       "      <td>66.220001</td>\n",
       "      <td>4888033</td>\n",
       "      <td>4888000</td>\n",
       "      <td>-2.8700</td>\n",
       "      <td>-4.15000</td>\n",
       "      <td>65.55</td>\n",
       "      <td>May 10, 19</td>\n",
       "      <td>-0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>70.5000</td>\n",
       "      <td>73.2000</td>\n",
       "      <td>67.1000</td>\n",
       "      <td>68.27</td>\n",
       "      <td>68.269997</td>\n",
       "      <td>6284516</td>\n",
       "      <td>6284500</td>\n",
       "      <td>-2.2300</td>\n",
       "      <td>-3.16000</td>\n",
       "      <td>69.02</td>\n",
       "      <td>May 09, 19</td>\n",
       "      <td>-0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>83.6100</td>\n",
       "      <td>85.3800</td>\n",
       "      <td>70.7850</td>\n",
       "      <td>72.25</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>14711809</td>\n",
       "      <td>14711800</td>\n",
       "      <td>-11.3600</td>\n",
       "      <td>-13.59000</td>\n",
       "      <td>78.53</td>\n",
       "      <td>May 08, 19</td>\n",
       "      <td>-0.135900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>77.1400</td>\n",
       "      <td>85.4500</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>79.17</td>\n",
       "      <td>79.169998</td>\n",
       "      <td>16532102</td>\n",
       "      <td>16532100</td>\n",
       "      <td>2.0300</td>\n",
       "      <td>2.63000</td>\n",
       "      <td>80.94</td>\n",
       "      <td>May 07, 19</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>62.7300</td>\n",
       "      <td>74.8400</td>\n",
       "      <td>62.5000</td>\n",
       "      <td>74.79</td>\n",
       "      <td>74.790001</td>\n",
       "      <td>8746178</td>\n",
       "      <td>8746200</td>\n",
       "      <td>12.0600</td>\n",
       "      <td>19.23000</td>\n",
       "      <td>69.11</td>\n",
       "      <td>May 06, 19</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>74.0000</td>\n",
       "      <td>65.6600</td>\n",
       "      <td>66.79</td>\n",
       "      <td>66.790001</td>\n",
       "      <td>13139367</td>\n",
       "      <td>13139400</td>\n",
       "      <td>-5.2100</td>\n",
       "      <td>-7.24000</td>\n",
       "      <td>69.44</td>\n",
       "      <td>May 03, 19</td>\n",
       "      <td>-0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>46.0000</td>\n",
       "      <td>72.9500</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>65.75</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>23118966</td>\n",
       "      <td>23119000</td>\n",
       "      <td>19.7500</td>\n",
       "      <td>42.93000</td>\n",
       "      <td>59.11</td>\n",
       "      <td>May 02, 19</td>\n",
       "      <td>0.429300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high      low   close    adjClose    volume  \\\n",
       "0  2019-05-31  100.0000  104.5500  97.2600  104.12  104.120003   7733863   \n",
       "1  2019-05-30  101.8965  105.2500  94.0300   98.59   98.589996  12359807   \n",
       "2  2019-05-29   90.0500   97.6500  87.3200   97.50   97.500000   8371994   \n",
       "3  2019-05-28   83.9800   88.8300  83.7000   86.00   86.000000   6604012   \n",
       "4  2019-05-24   83.9200   85.5000  79.5100   79.67   79.669998   2909494   \n",
       "5  2019-05-23   79.4000   83.8000  78.1227   82.10   82.099998   4331336   \n",
       "6  2019-05-22   77.3800   81.7400  77.0000   77.63   77.629997   3898382   \n",
       "7  2019-05-21   88.0300   88.7500  76.7600   77.50   77.500000   9065090   \n",
       "8  2019-05-20   88.9000   90.9600  83.1300   86.09   86.089996   5189713   \n",
       "9  2019-05-17   92.4600   96.6800  85.7100   89.35   89.349998  10718760   \n",
       "10 2019-05-16   90.1000   96.7845  89.5100   92.92   92.919998  13900335   \n",
       "11 2019-05-15   79.0000   93.0000  74.5500   86.92   86.919998  18356209   \n",
       "12 2019-05-14   72.4800   80.7500  71.1200   79.68   79.680000   7079600   \n",
       "13 2019-05-13   65.4600   71.9600  63.3600   69.50   69.500000   4784517   \n",
       "14 2019-05-10   69.0900   69.3323  61.6000   66.22   66.220001   4888033   \n",
       "15 2019-05-09   70.5000   73.2000  67.1000   68.27   68.269997   6284516   \n",
       "16 2019-05-08   83.6100   85.3800  70.7850   72.25   72.250000  14711809   \n",
       "17 2019-05-07   77.1400   85.4500  75.0000   79.17   79.169998  16532102   \n",
       "18 2019-05-06   62.7300   74.8400  62.5000   74.79   74.790001   8746178   \n",
       "19 2019-05-03   72.0000   74.0000  65.6600   66.79   66.790001  13139367   \n",
       "20 2019-05-02   46.0000   72.9500  45.0000   65.75   65.750000  23118966   \n",
       "\n",
       "    unadjustedVolume   change  changePercent    vwap       label  \\\n",
       "0            7733900   4.1200        4.12000  100.85  May 31, 19   \n",
       "1           12359800  -3.3065       -3.24000   99.98  May 30, 19   \n",
       "2            8372000   7.4500        8.27000   92.27  May 29, 19   \n",
       "3            6604000   2.0200        2.41000   86.20  May 28, 19   \n",
       "4            2909500  -4.2500       -5.06000   82.81  May 24, 19   \n",
       "5            4331300   2.7000        3.40000   80.97  May 23, 19   \n",
       "6            3898400   0.2500        0.32308   79.49  May 22, 19   \n",
       "7            9065100 -10.5300      -11.96000   80.23  May 21, 19   \n",
       "8            5189700  -2.8100       -3.16000   87.66  May 20, 19   \n",
       "9           10724100  -3.1100       -3.36000   90.67  May 17, 19   \n",
       "10          13900300   2.8200        3.13000   92.52  May 16, 19   \n",
       "11          18356200   7.9200       10.03000   85.89  May 15, 19   \n",
       "12           7079600   7.2000        9.93000   76.63  May 14, 19   \n",
       "13           4784500   4.0400        6.17000   68.91  May 13, 19   \n",
       "14           4888000  -2.8700       -4.15000   65.55  May 10, 19   \n",
       "15           6284500  -2.2300       -3.16000   69.02  May 09, 19   \n",
       "16          14711800 -11.3600      -13.59000   78.53  May 08, 19   \n",
       "17          16532100   2.0300        2.63000   80.94  May 07, 19   \n",
       "18           8746200  12.0600       19.23000   69.11  May 06, 19   \n",
       "19          13139400  -5.2100       -7.24000   69.44  May 03, 19   \n",
       "20          23119000  19.7500       42.93000   59.11  May 02, 19   \n",
       "\n",
       "    changeOverTime  \n",
       "0         0.041200  \n",
       "1        -0.032400  \n",
       "2         0.082700  \n",
       "3         0.024100  \n",
       "4        -0.050600  \n",
       "5         0.034000  \n",
       "6         0.003231  \n",
       "7        -0.119600  \n",
       "8        -0.031600  \n",
       "9        -0.033600  \n",
       "10        0.031300  \n",
       "11        0.100300  \n",
       "12        0.099300  \n",
       "13        0.061700  \n",
       "14       -0.041500  \n",
       "15       -0.031600  \n",
       "16       -0.135900  \n",
       "17        0.026300  \n",
       "18        0.192300  \n",
       "19       -0.072400  \n",
       "20        0.429300  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "ticker = \"BYND\"\n",
    "year = 2019\n",
    "month = 5\n",
    "\n",
    "# Get the stock history for the specified month\n",
    "df = stock_history(ticker, year, month)\n",
    "((df))# # Calculate the statistics if data is available\n",
    "# if not df.empty:\n",
    "#     percent_change, transaction_volume = stock_stats(df)\n",
    "#     print(\"Percent Change:\", percent_change)\n",
    "#     print(\"Transaction Volume:\", transaction_volume)\n",
    "# else:\n",
    "#     print(\"No data available for this period.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f48ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "932366f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 13)\n"
     ]
    }
   ],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for stock_history\n",
    "history = stock_history('BYND', 2019, 6)\n",
    "print(history.shape\n",
    ")# public test for stock_stats\n",
    "stats = stock_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1740b158",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a38a7",
   "metadata": {},
   "source": [
    "## Question 4 â€“ Comment Threads ðŸ§µ\n",
    "\n",
    "You regularly browse [Hacker News](https://news.ycombinator.com/) to keep up with the latest news in tech. One link to a Hacker News article is https://news.ycombinator.com/item?id=18344932. Note that this article has 18 comments and has a `storyid` of 18344932.\n",
    "\n",
    "The problem now is that you don't have internet access on your phone during your morning commute to work, so you want to save the interesting stories' comment threads beforehand in a CSV. You find their [API documentation](https://github.com/HackerNews/API) and decide to get to work.\n",
    "\n",
    "Complete the implementation of the function `get_comments`, which takes in a `storyid` and returns a DataFrame of all the comments below the news story. You can ignore \"dead\" comments(you will know them when you see them), as well as \"dead\" commentsâ€™ children. **Make sure the order of the comments in your DataFrame is from top to bottom just as you see on the website**. \n",
    "\n",
    "The DataFrame that `get_comments` returns should have 5 columns:\n",
    "1. `'id'`: The unique ID of the comment.\n",
    "2. `'by'`: The author of the comment.\n",
    "3. `'text'`: The actual comment.\n",
    "4. `'parent'`: The unique ID of the comment this comment is replying to.\n",
    "5. `'time'`: When the comment was created (in `pd.Timestamp` format).\n",
    "\n",
    "Some guidance:\n",
    "1. The URL to make requests to is `'https://hacker-news.firebaseio.com/v0/item/{}.json'`, however, the `{}` should be replaced with the ID of the article or page you are trying to access. \n",
    "2. Again, do not `import json` â€“ instead, use the `json` method on the Response object you get back.\n",
    "3. Use depth-first search when traversing the comments tree. You will have to do this manually, since you cannot use Beautiful Soup (which is only for HTML documents, not JSON objects).\n",
    "4. Make sure the length of your returned DataFrame is the same as value for the `'descendants'` key in the response JSON (both of which correspond to the number of comments for the story).\n",
    "5. You are allowed to use loops in this function. You may also want to create at least one helper function.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    You may find <a href=\"https://www.youtube.com/watch?v=uOfwW-onmpc\"><b>this hint video ðŸŽ¥</b></a> helpful!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5709b30-378f-4808-921b-2a3e1aa35289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by': 'ScottWRobinson', 'descendants': 18, 'id': 18344932, 'kids': [18380397, 18346406, 18348601, 18346750, 18346476, 18346746, 18346388], 'score': 47, 'time': 1540987334, 'title': 'TimescaleDB 1.0 Is Production Ready', 'type': 'story', 'url': 'https://blog.timescale.com/1-0-enterprise-production-ready-time-series-database-open-source-d32395a10cbf'}\n"
     ]
    }
   ],
   "source": [
    "# have the json attribute that appears from \"DFS'ing\" the comments being searched using the kids attribute of comments with replies\n",
    "\n",
    "story = 18344932 # i.e. args\n",
    "hh_url = f'https://hacker-news.firebaseio.com/v0/item/{story}.json'\n",
    "\n",
    "\n",
    "\n",
    "# print(hh_url)\n",
    "\n",
    "resp_hh = requests.get(hh_url)\n",
    "hh_tree = resp_hh.json()\n",
    "print(hh_tree)\n",
    "# keys to keep in final return df : id, by, text, parent, time\n",
    "# >>> dict_keys(['by', 'descendants', 'id', 'kids', 'score', 'time', 'title', 'type', 'url'])\n",
    "\n",
    "# id  obtained from this is title id\n",
    "# {'by': 'ScottWRobinson', 'descendants': 18, 'id': 18344932, 'kids': [18380397, 18346406, 18348601, 18346750, 18346476, 18346746, 18346388],\n",
    "# 'score': 47, 'time': 1540987334, 'title': 'TimescaleDB 1.0 Is Production Ready', 'type': 'story', 'url': 'https'}\n",
    "# ex : {'by': 'valyala', 'id': 18380397, 'parent': 18344932, 'text': 'TimescaleDB is great', 'time': 1541400799, 'type': 'comment'}\n",
    "# ex_2 : {... \"id\": 2}\n",
    "# and so on\n",
    "\n",
    "\n",
    "def dfs_traverse():\n",
    "    # TODO\n",
    "        # need to finish first and actually view wat dead comments are on the example site provided\n",
    "    # make pointers for wateva kids are discovered\n",
    "    return None\n",
    "\n",
    "# def get_comments(storyid):\n",
    "#     # don't return the \"dead\" comments in the output df \n",
    "#     return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff4ef4d4-68d5-47d7-b2ee-57ccd279092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def get_comment_data(comment_id: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Fetch comment data from Hacker News API for a given comment ID.\n",
    "    \n",
    "    Args:\n",
    "        comment_id (int): The ID of the comment to fetch\n",
    "        \n",
    "    Returns:\n",
    "        dict: Comment data from the API\n",
    "    \"\"\"\n",
    "    url = f'https://hacker-news.firebaseio.com/v0/item/{comment_id}.json'\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def traverse_comments(comment_id: int, comments_list: List[Dict]) -> None:\n",
    "    \"\"\"\n",
    "    Recursively traverse comment tree using DFS and collect all valid comments.\n",
    "    \n",
    "    Args:\n",
    "        comment_id (int): Current comment ID to process\n",
    "        comments_list (list): List to store valid comments\n",
    "    \"\"\"\n",
    "    comment_data = get_comment_data(comment_id)\n",
    "    \n",
    "    # Skip if comment is None or dead\n",
    "    if comment_data is None or comment_data.get('dead', False):\n",
    "        return\n",
    "        \n",
    "    # If it's a valid comment (not the story itself), add it to our list\n",
    "    if comment_data.get('type') == 'comment':\n",
    "        comments_list.append({\n",
    "            'id': comment_data.get('id'),\n",
    "            'by': comment_data.get('by'),\n",
    "            'text': comment_data.get('text'),\n",
    "            'parent': comment_data.get('parent'),\n",
    "            'time': pd.Timestamp(comment_data.get('time', 0), unit='s')\n",
    "        })\n",
    "    \n",
    "    # Recursively process child comments in order\n",
    "    for kid_id in comment_data.get('kids', []):\n",
    "        traverse_comments(kid_id, comments_list)\n",
    "\n",
    "def get_comments(storyid: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all comments for a given Hacker News story and return them as a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        storyid (int): The ID of the Hacker News story\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing all comments, ordered by DFS traversal\n",
    "    \"\"\"\n",
    "    # First, get the story data\n",
    "    story_data = get_comment_data(storyid)\n",
    "    \n",
    "    # Check if story exists and has comments\n",
    "    if not story_data or 'kids' not in story_data:\n",
    "        return pd.DataFrame(columns=['id', 'by', 'text', 'parent', 'time'])\n",
    "    \n",
    "    # List to store all comments\n",
    "    comments_list = []\n",
    "    \n",
    "    # Process each top-level comment in order\n",
    "    for comment_id in story_data['kids']:\n",
    "        traverse_comments(comment_id, comments_list)\n",
    "    \n",
    "    # Create DataFrame from collected comments\n",
    "    df = pd.DataFrame(comments_list)\n",
    "    \n",
    "    # Verify number of comments matches story's descendant count\n",
    "    # (excluding dead comments)\n",
    "    expected_count = story_data.get('descendants', 0)\n",
    "    if len(df) > expected_count:\n",
    "        # Trim excess comments if necessary\n",
    "        df = df.head(expected_count)\n",
    "    \n",
    "    return df[['id', 'by', 'text', 'parent', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01e48fe3-a0ad-4189-8673-eb6777f57e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18380397</td>\n",
       "      <td>valyala</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-11-05 06:53:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18346406</td>\n",
       "      <td>msiggy</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 15:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 19:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>18348601</td>\n",
       "      <td>2018-10-31 19:34:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>18348631</td>\n",
       "      <td>2018-10-31 20:23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>18348984</td>\n",
       "      <td>2018-10-31 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>18349540</td>\n",
       "      <td>2018-11-01 01:11:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18351061</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>18350673</td>\n",
       "      <td>2018-11-01 02:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 15:51:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18347260</td>\n",
       "      <td>nevi-me</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>18346750</td>\n",
       "      <td>2018-10-31 16:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18347555</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>18346750</td>\n",
       "      <td>2018-10-31 17:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18346476</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 15:27:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18346702</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>Sorry to hear, though I&amp;#x27;d like to mention...</td>\n",
       "      <td>18346476</td>\n",
       "      <td>2018-10-31 15:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18347232</td>\n",
       "      <td>grumpydba</td>\n",
       "      <td>Hi,&lt;p&gt;are the upcoming clustering efforts deve...</td>\n",
       "      <td>18346702</td>\n",
       "      <td>2018-10-31 16:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18349689</td>\n",
       "      <td>jason_slack</td>\n",
       "      <td>What were the specs of the machine you were us...</td>\n",
       "      <td>18346476</td>\n",
       "      <td>2018-10-31 22:16:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18346746</td>\n",
       "      <td>athenot</td>\n",
       "      <td>It would be nice if they did a quick compariso...</td>\n",
       "      <td>18344932</td>\n",
       "      <td>2018-10-31 15:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18346787</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>We do have comparisons, but judging by their M...</td>\n",
       "      <td>18346746</td>\n",
       "      <td>2018-10-31 15:56:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18346822</td>\n",
       "      <td>athenot</td>\n",
       "      <td>Thanks a lot, this is useful for comparing.&lt;p&gt;...</td>\n",
       "      <td>18346787</td>\n",
       "      <td>2018-10-31 16:00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           by                                               text  \\\n",
       "0   18380397      valyala  TimescaleDB is great for storing time series c...   \n",
       "1   18346406       msiggy  I&#x27;m excited to give this database a try i...   \n",
       "2   18348601      sman393  Can this be used side by side on normal Postgr...   \n",
       "3   18348631   RobAtticus  Yep, absolutely. Regular PostgreSQL tables coe...   \n",
       "4   18348984      sman393  Good to hear! how does the current TimescaleDB...   \n",
       "5   18349540   RobAtticus  Not sure I follow exactly what you&#x27;re ask...   \n",
       "6   18350673      sman393  Alright thanks! I thought I read that Timescal...   \n",
       "7   18351061   RobAtticus  It does not support sharding writes across mul...   \n",
       "8   18346750      zip1234  How fast is it when it has a TB of data? I rea...   \n",
       "9   18347260      nevi-me  I spent about 8 months writing data to TSDB. I...   \n",
       "10  18347555     dominotw  They have some numbers on their blog. Its very...   \n",
       "11  18346476     dominotw  I evaluated this heavily but had to backoff be...   \n",
       "12  18346702   RobAtticus  Sorry to hear, though I&#x27;d like to mention...   \n",
       "13  18347232    grumpydba  Hi,<p>are the upcoming clustering efforts deve...   \n",
       "14  18349689  jason_slack  What were the specs of the machine you were us...   \n",
       "15  18346746      athenot  It would be nice if they did a quick compariso...   \n",
       "16  18346787   RobAtticus  We do have comparisons, but judging by their M...   \n",
       "17  18346822      athenot  Thanks a lot, this is useful for comparing.<p>...   \n",
       "\n",
       "      parent                time  \n",
       "0   18344932 2018-11-05 06:53:19  \n",
       "1   18344932 2018-10-31 15:20:22  \n",
       "2   18344932 2018-10-31 19:29:39  \n",
       "3   18348601 2018-10-31 19:34:52  \n",
       "4   18348631 2018-10-31 20:23:46  \n",
       "5   18348984 2018-10-31 21:47:20  \n",
       "6   18349540 2018-11-01 01:11:59  \n",
       "7   18350673 2018-11-01 02:35:03  \n",
       "8   18344932 2018-10-31 15:51:43  \n",
       "9   18346750 2018-10-31 16:47:34  \n",
       "10  18346750 2018-10-31 17:19:34  \n",
       "11  18344932 2018-10-31 15:27:29  \n",
       "12  18346476 2018-10-31 15:47:41  \n",
       "13  18346702 2018-10-31 16:44:39  \n",
       "14  18346476 2018-10-31 22:16:27  \n",
       "15  18344932 2018-10-31 15:51:13  \n",
       "16  18346746 2018-10-31 15:56:39  \n",
       "17  18346787 2018-10-31 16:00:29  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931d8ea-86b6-4547-959d-393d72d5ca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f02a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92378192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "745d629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "comments = get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f96c033a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f0e4c",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 6! ðŸ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` â€“ that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q2 q4\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 2, and 4 â€“ again, only using the code in `lab.py`. [This video](https://www.loom.com/share/0ea254b85b2745e59322b5e5a8692e91?sid=5acc92e6-0dfe-4555-9b6a-8115b6a52f99) how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da78dd7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ea24e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ebf24-b183-48aa-925c-84e7fa82ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> os.path.exists('lab06_1.html')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q01_html = bs4.BeautifulSoup(open(\"lab06_1.html\", encoding='utf-8'), features='lxml')\n>>> len(q01_html.find_all('image')) == 0\nTrue",
         "failure_message": "you should not use the <image> tag to add images",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> extract_book_out[1] == extract_book_url\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(get_product_info_out, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 'Category' in get_product_info_out.keys()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> get_product_info_out['Rating'] == 'Two'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out.shape == (1, 11)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Rating'][0] == 'Four'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Title'][0] == 'Sharp Objects'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> history.shape == (20, 13)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> history.label.iloc[-1] == 'June 03, 19'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (len(stats[0]), len(stats[1])) == (7, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (float(stats[0][1:-1]) > 30) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> float(stats[1][:-1]) > 1 == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> stats[1][-1] == 'B'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> comments.shape == (18, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'by'] == 'RobAtticus'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'time'].day == 31\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
